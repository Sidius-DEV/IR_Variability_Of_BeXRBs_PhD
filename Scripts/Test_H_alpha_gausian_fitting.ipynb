{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussians python script:\n",
    "import math\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import voigt_profile\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.dpi']=300 # highres display\n",
    "from specutils import Spectrum1D\n",
    "from specutils.fitting import fit_generic_continuum as fgc\n",
    "from astropy import units as u\n",
    "from astropy.visualization import quantity_support\n",
    "import time\n",
    "quantity_support()\n",
    "from lmfit import Model\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# Script to perform multiple Gaussian/Lorentzian/Voigt fits on the, single/double peak H-alpha line (on the blue, center and red peak)\n",
    "\n",
    "file = np.loadtxt(r\".\\\\GX304-1\\\\smbxgpP201903220040_cr_cg_wr_01.txt\") # smbxgpP201206270016_cr_cg_wr_01.txt smbxgpP201401200077_cr_cg_wr_01.txt smbxgpP202001120152_cr_cg_wr_01.txt\n",
    "Source_Name=\"GX304-1\"\n",
    "x = file[:,0]\n",
    "y = file[:,1]\n",
    "\n",
    "\n",
    "def func_gaus(x, ctr, amp, wid): #Fitting function gaussian\n",
    "    y = np.zeros_like(x)\n",
    "    y = y + amp * np.exp( -((x - ctr)**2/wid**2))\n",
    "    return y\n",
    "def func_DoubleGaus(x, ctr, amp, wid,ctr2,amp2,wid2): #Fitting function gaussian\n",
    "    y = np.zeros_like(x)\n",
    "    y = y + amp * np.exp( -((x - ctr)**2/wid**2)) + amp2 * np.exp( -((x - ctr2)**2/wid2**2))\n",
    "    return y\n",
    "\n",
    "def func_lorentzian(x, ctr, amp, wid): #Fitting function lorentzian\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    y = y + amp * (0.5*wid**2/((x-ctr)**2+(0.5*wid)**2))\n",
    "    return y\n",
    "def func_DoubleLorentzian(x, ctr, amp, wid, ctr2, amp2, wid2): #Fitting function lorentzian\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    y = y + amp * (0.5*wid**2/((x-ctr)**2+(0.5*wid)**2)) + amp2 * (0.5*wid2**2/((x-ctr2)**2+(0.5*wid2)**2))\n",
    "    return y\n",
    "\n",
    "def func_voigt(x, ctr, amp, wid): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid-1\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp\n",
    "    return y\n",
    "def func_DoubleVoigt(x, ctr, amp, wid, ctr2, amp2, wid2): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid-1\n",
    "    gam2 = wid2-1\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp + voigt_profile(x - ctr2, wid2, gam2) * amp2\n",
    "    return y\n",
    "\n",
    "# def find_double_peak_coords(x_data,y_data): #Function to find P_0 guess values for double peak plotting\n",
    "    halpha_region_x = x_data[(x_data > 6540) & (x_data < 6590)]\n",
    "    halpha_region_y = y_data[(x_data > 6540) & (x_data < 6590)]\n",
    "\n",
    "    # print(halpha_region_x)\n",
    "\n",
    "    peaks, props = find_peaks(halpha_region_y)\n",
    "    # print(peaks)\n",
    "    peak_wavelengths=halpha_region_x[peaks]\n",
    "    peak_fluxes=halpha_region_y[peaks]\n",
    "    # print(\"The peak Wl and fluxes: \",peak_wavelengths,peak_fluxes)\n",
    "    \n",
    "    valleys, props = find_peaks(-halpha_region_y)\n",
    "    # print(valleys)\n",
    "    valley_wavelength=halpha_region_x[valleys]\n",
    "    valley_flux=halpha_region_y[valleys]\n",
    "    # print(valley_wavelength,valley_flux)\n",
    "\n",
    "    # --- Step 3: Pick the two largest peaks + the valley between\n",
    "    # Sort peaks by flux\n",
    "    sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "    selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "    # For the dip, just take min flux between the two peaks\n",
    "    left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "    mask = (halpha_region_x > left) & (halpha_region_x < right)\n",
    "    dip_idx = np.argmin(halpha_region_y[mask])\n",
    "    dip_wavelength = halpha_region_x[mask][dip_idx]\n",
    "    dip_flux = halpha_region_y[mask][dip_idx]\n",
    "\n",
    "    # --- Print results ---\n",
    "    print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "    print(\"Dip (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "    ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "    amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "    wid1=6*10\n",
    "    ctr2=valley_wavelength\n",
    "    ctr2=math.trunc(ctr2[0]*10)\n",
    "    wid2=0.5*((valley_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-valley_wavelength))\n",
    "    wid2=math.trunc(3*10)\n",
    "    ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "    amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "    wid3=4*10\n",
    "    amp2=dip_flux\n",
    "    # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "    amp2=math.trunc(amp2*-0.76689539232*10)\n",
    "\n",
    "    result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/8,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "    # result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "\n",
    "    # if len(peaks)==1:\n",
    "    #     # print(peak_wavelengths[0])\n",
    "    #     ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "    #     amp1=math.trunc(peak_fluxes[0]*10)\n",
    "    #     wid1=13.0*10\n",
    "\n",
    "    #     result=[ctr1/10,amp1/10-1,wid1/10]\n",
    "    #     print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def Smooth_find_single_valley_coords(x_data,y_data): #Function to find P_0 guess values for double or single peak plotting\n",
    "    print(\"We are in the valley finder!\")\n",
    "\n",
    "    valleys, _ = find_peaks(-y_data,distance=3)\n",
    "    print(valleys)\n",
    "    peak_wavelengths=x_data[valleys]\n",
    "    peak_fluxes=y_data[valleys]\n",
    "    if len(valleys)>1:\n",
    "        # Sort peaks by flux\n",
    "        sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "        selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "        # For the valley, just take min flux between the two peaks\n",
    "        left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "        mask = (x_data >= left) & (x_data <= right)\n",
    "        dip_idx = np.argmin(y_data[mask])\n",
    "        dip_wavelength = x_data[mask][dip_idx]\n",
    "        dip_flux = y_data[mask][dip_idx]\n",
    "\n",
    "        print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "        print(\"Valley (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "        ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "        amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "        wid1=6*10\n",
    "        ctr2=dip_wavelength\n",
    "        ctr2=math.trunc(ctr2*10)\n",
    "        wid2=0.3*((dip_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-dip_wavelength))\n",
    "        wid2=math.trunc(3*10)\n",
    "        ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "        amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "        wid3=4*10\n",
    "        amp2=dip_flux\n",
    "        # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "        amp2=math.trunc(amp2*0.76689539232*10)\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/10,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "        # result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "\n",
    "    if len(valleys)==1:\n",
    "        # print(peak_wavelengths[0])\n",
    "        ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "        amp1=math.trunc(peak_fluxes[0]*10)\n",
    "        wid1=5.0*10\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10]\n",
    "    # ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "    # amp1=math.trunc(peak_fluxes[0]*10)\n",
    "    # wid1=5.0*10\n",
    "\n",
    "    # result=[ctr1/10,amp1/10,wid1/10]\n",
    "    # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def Smooth_find_double_peak_coords(x_data,y_data): #Function to find P_0 guess values for double or single peak plotting\n",
    "    halpha_region_x = x_data[(x_data > 6553) & (x_data < 6572)]\n",
    "    halpha_region_y = y_data[(x_data > 6553) & (x_data < 6572)]\n",
    "\n",
    "    halpha_region_y=smooth(halpha_region_y,6)\n",
    "\n",
    "    peaks, _ = find_peaks(halpha_region_y,distance=3)\n",
    "    print(peaks)\n",
    "    peak_wavelengths=halpha_region_x[peaks]\n",
    "    peak_fluxes=halpha_region_y[peaks]\n",
    "\n",
    "    if len(peaks)>1:\n",
    "        # Sort peaks by flux\n",
    "        sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "        selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "        # For the valley, just take min flux between the two peaks\n",
    "        left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "        mask = (halpha_region_x >= left) & (halpha_region_x <= right)\n",
    "        dip_idx = np.argmin(halpha_region_y[mask])\n",
    "        dip_wavelength = halpha_region_x[mask][dip_idx]\n",
    "        dip_flux = halpha_region_y[mask][dip_idx]\n",
    "\n",
    "        # print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "        # print(\"Valley (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "        ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "        amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "        wid1=6*10\n",
    "        ctr2=dip_wavelength\n",
    "        ctr2=math.trunc(ctr2*10)\n",
    "        wid2=0.3*((dip_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-dip_wavelength))\n",
    "        wid2=math.trunc(3*10)\n",
    "        ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "        amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "        wid3=4*10\n",
    "        amp2=dip_flux\n",
    "        # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "        amp2=math.trunc(amp2*0.76689539232*10)\n",
    "\n",
    "        # result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/10,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "        result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "        print(\"3 component guess: \",result)\n",
    "\n",
    "    if len(peaks)==1:\n",
    "        # print(peak_wavelengths[0])\n",
    "        ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "        amp1=math.trunc(peak_fluxes[0]*10)\n",
    "        wid1=5.0*10\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10]\n",
    "        print(\"Single peak guess: \",result)\n",
    "\n",
    "    if len(peaks)==0:\n",
    "        result=Smooth_find_single_valley_coords(halpha_region_x,halpha_region_y)\n",
    "        print(\"result found no peaks, maybe only one big valley?\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def spec_normalisation(x,y):\n",
    "\n",
    "\n",
    "    ########### Function to normalise spectrum by dividing with fitted continuum (NTE this should only be done if imported data is not already normalised):\n",
    "    s1_cal=y*u.Unit('erg cm-2 s-2 AA-1') #flux data\n",
    "    wav_cal = x*u.AA #wavelength data\n",
    "\n",
    "    spec=Spectrum1D(spectral_axis=wav_cal,flux=s1_cal)\n",
    "    s_fit=fgc(spec,median_window=1)\n",
    "    y_cont_fitted=s_fit(wav_cal)\n",
    "    print(len(spec.spectral_axis.value))\n",
    "    # print(find_double_peak_coords(spec.spectral_axis.value,(spec.flux/y_cont_fitted).value))\n",
    "\n",
    "\n",
    "    fig=plt.figure(figsize=(8,5)) #create the figure\n",
    "    # plt.yscale(\"log\") #set y scale to log to correctly display the spectra\n",
    "    plt.plot(spec.spectral_axis, spec.flux, label='spectra')\n",
    "    plt.plot(wav_cal, y_cont_fitted, label='fitted continuum')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    #now plot normalised spectra\n",
    "    fig=plt.figure(figsize=(8,5)) #create the figure\n",
    "\n",
    "    plt.plot(spec.spectral_axis, spec.flux/y_cont_fitted, label='Normalized spectra')\n",
    "    plt.legend()\n",
    "    # plt.yscale(\"log\") #set y scale to log to correctly display the spectra\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return spec.spectral_axis.value, (spec.flux/y_cont_fitted).value\n",
    "    ###########\n",
    "\n",
    "def fit_ALL_t1(Source_Name, nameString, guess, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_gaus, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_GAUS = func_gaus(x, *popt)\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label='H{alpha}')\n",
    "    plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "    plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_gaus(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_lorentzian, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_LORERTZIAN = func_lorentzian(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Average between GAUS and LORERNTZ fits, plot only:\n",
    "    fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_Average_Gaus_Lor_Fit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    popt, pcov = curve_fit(func_voigt, x, y, p0=guess,maxfev=50000)\n",
    "    fit_VOIGT = func_voigt(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "\n",
    "    \n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_voigt(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "def fit_ALL_t2(Source_Name, nameString, guess, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleGaus, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_GAUS = func_DoubleGaus(x, *popt)\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label='H{alpha}')\n",
    "    plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "    plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_gaus(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleLorentzian, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_LORERTZIAN = func_DoubleLorentzian(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Average between GAUS and LORERNTZ fits, plot only:\n",
    "    fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_Average_Gaus_Lor_Fit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleVoigt, x, y, p0=guess,maxfev=50000)\n",
    "    fit_VOIGT = func_DoubleVoigt(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "\n",
    "    \n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_voigt(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "xmin,xmax = 6550,6575\n",
    "ymin,ymax=-4.5,2\n",
    "graph_W,graph_H = 8,5\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H))\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y,'o')\n",
    "\n",
    "plt.plot(x, smooth(y,3), 'ro', lw=2)\n",
    "\n",
    "plt.plot(x, smooth(y,8), 'go', lw=1.5)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0940bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Gaussian, Lorentzian, average between Gaussian and Lorentzian, Voigt fit, in one function with plots\n",
    "###########and saving them as named figures including source name and date observed\n",
    "\n",
    "\n",
    "workdir = pathlib.Path(r\"C:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\")\n",
    "# Image_Dir= str(workdir)+\"\\\\\"+Source_Name\n",
    "Image_Dir= str(workdir)\n",
    "print(Image_Dir)\n",
    "\n",
    "# .glob() produces a generator too\n",
    "workdir.glob(\"*\")\n",
    "\n",
    "\n",
    "spectra_files=list(workdir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "# print ((spectra_files))\n",
    "for i in range(0,len(spectra_files)):\n",
    "    file_Names.append(str(spectra_files[i])[66:])\n",
    "print(\"File names:\",file_Names)\n",
    "\n",
    "\n",
    "guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "print(file)\n",
    "\n",
    "\n",
    "for i in range(0,len(file_Names)):\n",
    "    file = np.loadtxt(str(file_Names[i])) # smbxgpP201206270016_cr_cg_wr_01.txt smbxgpP201401200077_cr_cg_wr_01.txt smbxgpP202001120152_cr_cg_wr_01.txt\n",
    "    Source_Name=\"GX304-1\"\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "    guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    nameString = file_Names[i][15:27] + '_' + Source_Name\n",
    "    print(nameString)\n",
    "    if(len(guess)==3):\n",
    "        fit_ALL_t1(Source_Name, nameString, guess, x, y)\n",
    "    if(len(guess)==6):\n",
    "        fit_ALL_t2(Source_Name, nameString, guess, x, y)\n",
    "    time.sleep(0.1)\n",
    "    # break\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Gaussian fitting and plot:\n",
    "# guess = [6555.0, 1.4, 6.0, 6561.0, -1.0, 3.0, 6565.0, 1.6, 4.0]\n",
    "guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "popt, pcov = curve_fit(func_gaus, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_GAUS = func_gaus(x, *popt)\n",
    "\n",
    "########## Error analysis and inclusion in model (can be excluded to go straight to plot):\n",
    "########## Need to find the correct way to get SALT errors on the y data.\n",
    "# yerr_data= np.sqrt((spec.flux/y_cont_fitted).value)\n",
    "# fig=plt.figure(figsize=(16, 9)) #create the figure\n",
    "# plt.xlabel('Wavelength (Angstroms)')\n",
    "# plt.ylabel('Normalised flux')\n",
    "# plt.xlim(6520,6600)\n",
    "# plt.errorbar(spec.spectral_axis.value, (spec.flux/y_cont_fitted).value, yerr_data, ls='', color='k')\n",
    "# plt.scatter(spec.spectral_axis.value, (spec.flux/y_cont_fitted).value, s=7, zorder=1000)\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.grid('minor')\n",
    "\n",
    "plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label='H{alpha}')\n",
    "plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_gaus(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Gaussian_demo.png')\n",
    "###########\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Lorentzian fitting and plot:\n",
    "# guess = [6555, 1.4, 6.0, 6561.0, -1.1, 3.0, 6565.0, 1.6, 4.0]\n",
    "print(guess)\n",
    "\n",
    "popt, pcov = curve_fit(func_lorentzian, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_LORERTZIAN = func_lorentzian(x, *popt)\n",
    "\n",
    "plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.grid('minor')\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y, 'r-', linewidth=1)\n",
    "plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "plt.legend()\n",
    "plt.savefig('Lorentzian_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Average between GAUS and LORERNTZ fits, plot only:\n",
    "\n",
    "fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.grid('minor')\n",
    "plt.plot(x, y, 'r-', linewidth=1)\n",
    "plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "plt.legend()\n",
    "plt.savefig('Average_GAUS_LORENTZ_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53533",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Voigt fitting and plot:\n",
    "print(guess)\n",
    "\n",
    "popt, pcov = curve_fit(func_voigt, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_VOIGT = func_voigt(x, *popt)\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.grid('minor')\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y, 'r-', linewidth=1)\n",
    "plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_voigt(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "plt.legend()\n",
    "plt.savefig('Voigt_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def double_voigt(x, amp1, cen1, sig1, gam1, amp2, cen2, sig2, gam2):\n",
    "    \"\"\"\n",
    "    A function representing the sum of two Voigt profiles.\n",
    "    Parameters:\n",
    "        x (array_like): The independent variable (e.g., wavelength, energy).\n",
    "        amp1, cen1, sig1, gam1 (float): Parameters for the first Voigt profile.\n",
    "        amp2, cen2, sig2, gam2 (float): Parameters for the second Voigt profile.\n",
    "    Returns:\n",
    "        array_like: The sum of two Voigt profiles at given x values.\n",
    "    \"\"\"\n",
    "    return voigt_profile(x - cen1, sig1, gam1) * amp1 + \\\n",
    "           voigt_profile(x - cen2, sig2, gam2) * amp2\n",
    "\n",
    "# Example usage with dummy data\n",
    "# Replace with your actual x_data and y_data\n",
    "x_data = np.linspace(0, 100, 500)\n",
    "# Create some noisy double-peaked data for demonstration\n",
    "y_data = (voigt_profile(x_data - 30, 5, 2) * 100 +\n",
    "          voigt_profile(x_data - 70, 4, 3) * 70 +\n",
    "          np.random.normal(0, 2, len(x_data)))\n",
    "\n",
    "# Initial guesses for the 8 parameters\n",
    "# (amp1, cen1, sig1, gam1, amp2, cen2, sig2, gam2)\n",
    "initial_guesses = [90, 30, 5, 2, 60, 70, 4, 3]\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(double_voigt, x_data, y_data, p0=initial_guesses)\n",
    "print(popt)\n",
    "\n",
    "fit = double_voigt(x_data, 113.90545215,  30.02391812,   4.34510307,   3.86406725,  71.52031152,  70.67003695,   5.77831164 ,  1.13183806)\n",
    "\n",
    "fig=plt.figure(figsize=(16, 9)) #create the figure\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "# plt.xlim(6520,6600)\n",
    "plt.plot(x_data, y_data, 'r-', linewidth=1)\n",
    "plt.plot(x_data, fit , 'b-', linewidth=2, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b61330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas python script:\n",
    "from scipy.integrate import quad\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "#This script calculates the blue and red surface areas and these are compared with the measured equivalent widths\n",
    "#Equations A.17 and A.18\n",
    "\n",
    "file = np.loadtxt('HR_ave_velocities.dat')\n",
    "file2 = np.loadtxt('HR_ave_EW.dat')\n",
    "\n",
    "\n",
    "MJD = file[:,0]\n",
    "#cycles = file[:,1]\n",
    "v_blue = file[:,2]\n",
    "v_red = file[:,3]\n",
    "\n",
    "EW_blue = file2[:,2]\n",
    "EW_red = file2[:,3]\n",
    "\n",
    "MJD_eph = 43366.275\n",
    "\n",
    "\n",
    "def integrand(x,eccen):\n",
    "    return 1.0/((1.0 + eccen*np.cos(x))**2)\n",
    "\n",
    "ep = 0.4\n",
    "\n",
    "#print I[0]\n",
    "\n",
    "a_in = 1.0/(1.0 - ep)\n",
    "inc = 0.52\n",
    "v_crit = 525.0\n",
    "degtorad = np.pi/180.0\n",
    "radtodeg = 180.0/np.pi\n",
    "\n",
    "g = open(\"HR_Areas_ave_out.txt\",\"w\")\n",
    "for i in range(len(MJD)):\n",
    "    t1 = ((2.0*v_crit)/(v_red[i] - v_blue[i]))**2\n",
    "    t2 = ((np.sin(inc))**2)/(1.0 - ep**2)\n",
    "    a_p = t1*t2\n",
    "    ts1 = 0.5*(a_p**2 - a_in**2)*(1.0 - ep**2)*np.cos(inc)\n",
    "    MJD_conv = MJD[i] - 2400000.5\n",
    "    ratio = ((v_red[i]+v_blue[i])/(v_red[i]-v_blue[i]))\n",
    "    om = np.arccos(ratio*(1.0/ep))\n",
    "    cos_om = ratio*(1.0/ep)\n",
    "    f01 = np.arccos(-ep*cos_om) - om\n",
    "    f01_deg = f01*radtodeg\n",
    "    \n",
    "    f02 = (2.0*np.pi - np.arccos(-ep*cos_om)) - om\n",
    "    f02_deg = f02*radtodeg\n",
    "    \n",
    "    \n",
    "    I_b = quad(integrand,f01,f02,args=(ep))\n",
    "    ts2 = I_b[0]\n",
    "    S_blue = ts1*ts2\n",
    "    I_r = quad(integrand,f02,f01+2.0*np.pi,args=(ep))\n",
    "    ts3 = I_r[0]\n",
    "    S_red = ts1*ts3\n",
    "    ratio_areas = S_blue/S_red\n",
    "    ratio_EW = EW_blue[i]/EW_red[i]\n",
    "    g.write(\"%0.3f  %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f\\n\" %(MJD[i],S_blue,S_red,EW_blue[i],EW_red[i],ratio_areas,ratio_EW,I_b[0],I_r[0],f01_deg,f02_deg))\n",
    "g.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def map_DEG_to_RA(deg_list):\n",
    "    RA_list=[]\n",
    "    coord=0\n",
    "    for i in range(0,len(deg_list)):\n",
    "        hour= (deg_list[i]//1)*(1/15) #get the integer part of the float degree value and convert to hours. (1/15 hours per degree)\n",
    "        minute= (hour-hour//1)*4.0 #decimal part of the degree float converted to minutes (4 minutes per degree)\n",
    "        second= (minute-minute//1)*60 #decimal part of the minute coordinate, converted to seconds coordinate (60 sec per minute)\n",
    "        coord=hour//1+(minute//1)/100+((second//1)//1)/10000\n",
    "        RA_list.append(coord)\n",
    "    return(RA_list)\n",
    "\n",
    "print(map_DEG_to_RA([22.2565,23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing code\n",
    "x = np.linspace(0,2*np.pi,100)\n",
    "y = np.sin(x) + np.random.random(100) * 0.8\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "plt.plot(x, y,'o')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "plt.plot(x, smooth(y,3), 'r-', lw=2)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "plt.plot(x, smooth(y,19), 'g-', lw=2)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "089f6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "import dateutil.parser\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Model\n",
    "from lmfit.models import GaussianModel\n",
    "from lmfit.models import LorentzianModel\n",
    "from lmfit.models import VoigtModel\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import voigt_profile\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "xmin,xmax = 6520,6600\n",
    "ymin,ymax=-4.5,2\n",
    "graph_W,graph_H = 8,5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd594ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This segment opens the csv database and populates the spectrum filepaths and Julian dates, OVERWRITES THINGS, BE CAREFUL!\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_name) #Add the source folder sub directory to save the work to\n",
    "# print(f\"Image saving directory for source {Source_name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_name}_dataframe.csv') #read the specific source database csv file\n",
    "# print((f'{Image_Dir}\\{Source_name}_dataframe.csv'))\n",
    "# print(Source_database)\n",
    "\n",
    "#populate the Spec_Path column with the spectra that are present in the Image_Dir directory:\n",
    "\n",
    "spectra_files=list(Image_Dir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "for i in range(0,len(spectra_files)):\n",
    "    Source_database.loc[i,\"Spec_Path\"]=str(spectra_files[i])[74:] #Save the spectrum txt file path into the Spec_Path column\n",
    "    dt = dateutil.parser.parse(str(spectra_files[i])[81:89]) #Parse the date from the file name string\n",
    "    time = astropy.time.Time(dt) \n",
    "    Source_database.loc[i,\"JD\"]=str(int(time.jd)) #Save into the database as the Julian date for timeseries plots later\n",
    "    file_Names.append(str(spectra_files[i])[74:])\n",
    "print(\"File names:\",Source_database[\"JD\"])\n",
    "\n",
    "Source_database.to_csv(f'{Image_Dir}\\{Source_name}_dataframe.csv',index=False) #THIS SAVES AND OVERWRITES WHATEVER VALUES HAVE BEEN READ INTO THE DATABASE! BE CAREFUL WITH IT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe51a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REDUNDANT, MIGHT DELETE THIS CELL!  This segmnent reads from the csv database and analyses the spectra\n",
    "\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_name) #Add the source folder sub directory to save the work to\n",
    "# print(f\"Image saving directory for source {Source_name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_name}_dataframe.csv') #read the specific source database csv file\n",
    "\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "\n",
    "    p=Source_database[\"Spec_Path\"][i]\n",
    "    print(f\"{Image_Dir}\\{p}\")\n",
    "    file = np.loadtxt(str(f\"{Image_Dir}\\{p}\")) # This imports the wavelength and normalised flux lists from each spectrum file listed in the database\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "\n",
    "    #If statements to determine which kind of fit to do depending on \"type\" or the shape of the Halpha line profile\n",
    "    if(Source_database[\"Type\"][i]==1):\n",
    "        print(\"Single emission peak type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==2):\n",
    "        print(\"Double emission peak type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==3):\n",
    "        print(\"Single absorption valley type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==4):\n",
    "        print(\"Absorption valley walled by emission wings type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==5):\n",
    "        print(\"Emission peak walled by absorption wings type spectrum\")\n",
    "\n",
    "    # guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    # nameString = file_Names[i][15:27] + '_' + Source_Name\n",
    "    # print(nameString)\n",
    "    # if(len(guess)==3):\n",
    "    #     fit_ALL_t1(Source_Name, nameString, guess, x, y)\n",
    "    # if(len(guess)==6):\n",
    "    #     fit_ALL_t2(Source_Name, nameString, guess, x, y)\n",
    "    time.sleep(0.1)\n",
    "    # break\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb14723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Main LMFit segment starts here\n",
    "\n",
    "printTypeOnGraph=0 #This is just a variable that tells the plots to indicate the type of spectrum from 1 to 5 if variable is set to 1.\n",
    "\n",
    "def LMFIT_gaussian(x, amp, cen, wid): # as defined in documentation https://lmfit.github.io/lmfit-py/builtin_models.html#gaussianmodel\n",
    "\n",
    "    return (amp / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x-cen)**2 / (2*wid**2))\n",
    "\n",
    "def LMFIT_lorentzian(x, amp, cen, wid): # as defined in documentation https://lmfit.github.io/lmfit-py/builtin_models.html#lorentzianmodel\n",
    "\n",
    "    return ((amp/np.pi)*(wid/((x-cen)**2+wid**2)))\n",
    "\n",
    "#The Voigt model is internally defined for LMfit modules, see https://lmfit.github.io/lmfit-py/builtin_models.html#voigtmodel\n",
    "def func_voigt(x, amp, ctr, wid): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp\n",
    "    return y\n",
    "\n",
    "def LMFIT_t1_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 1 spectra with single emission peak\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the single peak gaussian component\n",
    "\n",
    "    model = gmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=25, min=0)\n",
    "    params['g1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['g1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['g1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value]\n",
    "\n",
    "def LMFIT_t1_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 1 spectra with single emission peak\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the single peak lorentzian component\n",
    "\n",
    "    model = lmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=25, min=0)\n",
    "    params['l1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['l1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['l1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Lorentzian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value]\n",
    "\n",
    "def LMFIT_t1_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 1 spectra with single emission peak\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the single peak voigt component\n",
    "\n",
    "    model = vmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=25, min=0)\n",
    "    params['v1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['v1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['v1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value]\n",
    "\n",
    "\n",
    "def LMFIT_t2_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 2 spectra with double emission peak\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the first peak gaussian component\n",
    "    gmodel2 = GaussianModel(prefix='g2_') # Define the second peak gaussian component\n",
    "\n",
    "    model = gmodel1 + gmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=20, min=0)\n",
    "    params['g1_center'].set(value=6555, min=6550, max=6562)\n",
    "    params['g1_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['g2_amplitude'].set(value=20, min=0)\n",
    "    params['g2_center'].set(value=6563, min=6558, max=6575)\n",
    "    params['g2_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['g1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_gaussian(x, result.params['g1_amplitude'].value, result.params['g1_center'].value, result.params['g1_sigma'].value)\n",
    "    result2= LMFIT_gaussian(x, result.params['g2_amplitude'].value, result.params['g2_center'].value, result.params['g2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Gaussian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,\n",
    "            result.params['g2_height'].value, result.params['g2_center'].value, result.params['g2_sigma'].value]\n",
    "\n",
    "def LMFIT_t2_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 2 spectra with double emission peak\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the first peak Lorentzian component\n",
    "    lmodel2 = LorentzianModel(prefix='l2_') # Define the second peak Lorentzian component\n",
    "\n",
    "    model = lmodel1 + lmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=20, min=0)\n",
    "    params['l1_center'].set(value=6555, min=6550, max=6562)\n",
    "    params['l1_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    # Set initial guesses for the second Lorentzian\n",
    "    params['l2_amplitude'].set(value=20, min=0)\n",
    "    params['l2_center'].set(value=6563, min=6558, max=6575)\n",
    "    params['l2_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_lorentzian(x, result.params['l1_amplitude'].value, result.params['l1_center'].value, result.params['l1_sigma'].value)\n",
    "    result2= LMFIT_lorentzian(x, result.params['l2_amplitude'].value, result.params['l2_center'].value, result.params['l2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Lorentzian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,\n",
    "            result.params['l2_height'].value, result.params['l2_center'].value, result.params['l2_sigma'].value]\n",
    "\n",
    "def LMFIT_t2_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 2 spectra with double emission peak\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the first peak Voigt component\n",
    "    vmodel2 = VoigtModel(prefix='v2_') # Define the second peak Voigt component\n",
    "\n",
    "    model = vmodel1 + vmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=20, min=0)\n",
    "    params['v1_center'].set(value=6555, min=6550, max=6561)\n",
    "    params['v1_sigma'].set(value=3, min=0, max=5)\n",
    "\n",
    "    # Set initial guesses for the second Voigt\n",
    "    params['v2_amplitude'].set(value=20, min=0)\n",
    "    params['v2_center'].set(value=6561, min=6558, max=6575)\n",
    "    params['v2_sigma'].set(value=3, min=0, max=5)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= func_voigt(x, result.params['v1_amplitude'].value, result.params['v1_center'].value, result.params['v1_sigma'].value)\n",
    "    result2= func_voigt(x, result.params['v2_amplitude'].value, result.params['v2_center'].value, result.params['v2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Voigt best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,\n",
    "            result.params['v2_height'].value, result.params['v2_center'].value, result.params['v2_sigma'].value]\n",
    "\n",
    "\n",
    "def LMFIT_t3_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the single valley gaussian component\n",
    "\n",
    "    model = gmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=-25, max=0)\n",
    "    params['g1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['g1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['g1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value]\n",
    "\n",
    "def LMFIT_t3_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the single valley lorentzian component\n",
    "\n",
    "    model = lmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=-25, max=0)\n",
    "    params['l1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['l1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['l1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Lorentzian Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value]\n",
    "\n",
    "def LMFIT_t3_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the single valley voigt component\n",
    "\n",
    "    model = vmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=-25, max=0)\n",
    "    params['v1_center'].set(value=6562, min=6555, max=6575)\n",
    "    params['v1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['v1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6550) & (x < 6575)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r-', linewidth=1)\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "    plt.legend()\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value]\n",
    "\n",
    "def LMfit_ALL_t1(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t1_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t1_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t1_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "def LMfit_ALL_t2(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t2_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t2_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t2_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "def LMfit_ALL_t3(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t3_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t3_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t3_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "    \n",
    "    return (\"finished \"+nameString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd1ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial work directory:  c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\n",
      "File names: ['GX304-1\\\\smbxgpP201206270016_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201206270017_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201301240111_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201301240112_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303060077_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303060078_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303230069_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303230070_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201304270055_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201304270056_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201401200076_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201401200077_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402160001_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402160002_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402270028_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402270029_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403100009_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403100010_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403220152_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403220153_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404050094_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404050095_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404160072_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404160073_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405030027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405030028_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405110039_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405110040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405140003_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405140004_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405170012_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405170013_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405310014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405310015_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406100025_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406100026_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406130030_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501150046_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501150047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501200020_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501200021_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502030011_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502030012_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502110013_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502110014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502190017_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502190018_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502250026_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502250027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606010027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606170033_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606180053_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606240033_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606290014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201701250174_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201702150044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201703140037_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201703310052_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201704130054_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201706050039_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201707010034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201707110044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201801160059_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201805230058_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201806250047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201901270047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902060059_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902160083_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902260045_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201903110041_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201903220040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202001120152_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202003180084_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202006030040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202007010055_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202007280246_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202204010106_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202204010107_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202206190042_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202206190043_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207130034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207130035_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207270043_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207270044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202208040034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202208040035_cr_cg_wr_01.txt']\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201206270016_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201206270017_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201301240111_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201301240112_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303060077_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303060078_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303230069_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303230070_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201304270055_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201304270056_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201401200076_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201401200077_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201402160001_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201402160002_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201402270028_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201402270029_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201403100009_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201403100010_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201403220152_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201403220153_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201404050094_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201404050095_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201404160072_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201404160073_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405030027_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405030028_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405110039_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405110040_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405140003_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405140004_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405170012_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405170013_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405310014_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201405310015_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201406100025_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201406100026_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201406130030_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201501150046_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201501150047_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201501200020_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201501200021_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502030011_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502030012_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502110013_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502110014_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502190017_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502190018_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502250026_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201502250027_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201606010027_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201606170033_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201606180053_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201606240033_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201606290014_cr_cg_wr_01.txt\n",
      "Emission peak walled by absorption wings type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201701250174_cr_cg_wr_01.txt\n",
      "Single absorption valley type spectrum\n",
      "-1.88945258850936\n",
      "[[Model]]\n",
      "    Model(gaussian, prefix='g1_')\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 22\n",
      "    # data points      = 3172\n",
      "    # variables        = 3\n",
      "    chi-square         = 667.953651\n",
      "    reduced chi-square = 0.21077742\n",
      "    Akaike info crit   = -4935.65498\n",
      "    Bayesian info crit = -4917.46863\n",
      "    R-squared          = 0.12989771\n",
      "[[Variables]]\n",
      "    g1_amplitude: -22.0928058 +/- 1.15740502 (5.24%) (init = -25)\n",
      "    g1_center:     6561.28647 +/- 0.28212163 (0.00%) (init = 6562)\n",
      "    g1_sigma:      4.66471338 +/- 0.28213823 (6.05%) (init = 10)\n",
      "    g1_fwhm:       10.9845604 +/- 0.66438474 (6.05%) == '2.3548200*g1_sigma'\n",
      "    g1_height:    -1.88945259 +/- 0.09897465 (5.24%) == '0.3989423*g1_amplitude/max(1e-15, g1_sigma)'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(g1_amplitude, g1_sigma) = -0.5774\n",
      "-2.0204312739001664\n",
      "[[Model]]\n",
      "    Model(lorentzian, prefix='l1_')\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 41\n",
      "    # data points      = 3172\n",
      "    # variables        = 3\n",
      "    chi-square         = 672.981613\n",
      "    reduced chi-square = 0.21236403\n",
      "    Akaike info crit   = -4911.86745\n",
      "    Bayesian info crit = -4893.68110\n",
      "    R-squared          = 0.12334810\n",
      "[[Variables]]\n",
      "    l1_amplitude: -27.9427992 +/- 1.73556007 (6.21%) (init = -25)\n",
      "    l1_center:     6561.22148 +/- 0.27347491 (0.00%) (init = 6562)\n",
      "    l1_sigma:      4.40226290 +/- 0.38674357 (8.79%) (init = 10)\n",
      "    l1_fwhm:       8.80452580 +/- 0.77348715 (8.79%) == '2.0000000*l1_sigma'\n",
      "    l1_height:    -2.02043127 +/- 0.12550948 (6.21%) == '0.3183099*l1_amplitude/max(1e-15, l1_sigma)'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(l1_amplitude, l1_sigma) = -0.7071\n",
      "-1.9393084070433266\n",
      "[[Model]]\n",
      "    Model(voigt, prefix='v1_')\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 43\n",
      "    # data points      = 3172\n",
      "    # variables        = 3\n",
      "    chi-square         = 669.888774\n",
      "    reduced chi-square = 0.21138806\n",
      "    Akaike info crit   = -4926.47869\n",
      "    Bayesian info crit = -4908.29234\n",
      "    R-squared          = 0.12737695\n",
      "[[Variables]]\n",
      "    v1_amplitude: -25.8935074 +/- 1.47329048 (5.69%) (init = -25)\n",
      "    v1_center:     6561.26274 +/- 0.28327554 (0.00%) (init = 6562)\n",
      "    v1_sigma:      2.78667142 +/- 0.20634050 (7.40%) (init = 10)\n",
      "    v1_gamma:      2.78667142 +/- 0.20634050 (7.40%) == 'v1_sigma'\n",
      "    v1_fwhm:       10.0356137 +/- 0.74309211 (7.40%) == '1.0692*v1_gamma+sqrt(0.8664*v1_gamma**2+5.545083*v1_sigma**2)'\n",
      "    v1_height:    -1.93930841 +/- 0.11032564 (5.69%) == '(v1_amplitude/(max(1e-15, v1_sigma*sqrt(2*pi))))*real(wofz((1j*v1_gamma)/(max(1e-15, v1_sigma*sqrt(2)))))'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(v1_amplitude, v1_sigma) = -0.6508\n",
      "end of plotting\n"
     ]
    }
   ],
   "source": [
    "##### This segmnent reads from the csv database and analyses the spectra\n",
    "\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_Name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_Name) #Add the source folder sub directory to save the work to\n",
    "# print(f\"Image saving directory for source {Source_Name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_Name}_dataframe.csv') #read the specific source database csv file\n",
    "\n",
    "spectra_files=list(Image_Dir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "# print ((spectra_files))\n",
    "for i in range(0,len(spectra_files)):\n",
    "    file_Names.append(str(spectra_files[i])[66:])\n",
    "print(\"File names:\",file_Names)\n",
    "\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "\n",
    "    p=Source_database[\"Spec_Path\"][i]\n",
    "    print(f\"{Image_Dir}\\{p}\")\n",
    "    file = np.loadtxt(str(f\"{Image_Dir}\\{p}\")) # This imports the wavelength and normalised flux lists from each spectrum file listed in the database\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "    nameString = file_Names[i][15:27] + '_' + Source_Name\n",
    "\n",
    "    #If statements to determine which kind of fit to do depending on \"type\" or the shape of the Halpha line profile\n",
    "    if(Source_database[\"Type\"][i]==1):\n",
    "        print(\"Single emission peak type spectrum\")\n",
    "        # LMfit_ALL_t1(Source_Name,nameString,x,y)\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==2):\n",
    "        print(\"Double emission peak type spectrum\")\n",
    "        # LMfit_ALL_t2(Source_Name, nameString, x, y)\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==3):\n",
    "        print(\"Single absorption valley type spectrum\")\n",
    "        LMfit_ALL_t3(Source_Name, nameString, x, y)\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==4):\n",
    "        print(\"Absorption valley walled by emission wings type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==5):\n",
    "        print(\"Emission peak walled by absorption wings type spectrum\")\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    if (Source_database[\"Type\"][i]==3):\n",
    "        break\n",
    "    # break\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1300d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
