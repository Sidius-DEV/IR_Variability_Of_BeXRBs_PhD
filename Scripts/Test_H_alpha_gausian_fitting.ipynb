{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCIPY implimentation segment starting with Gaussians python script from Itu:\n",
    "import math\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import voigt_profile\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.dpi']=300 # highres display\n",
    "from specutils import Spectrum1D\n",
    "from specutils.fitting import fit_generic_continuum as fgc\n",
    "from astropy import units as u\n",
    "from astropy.visualization import quantity_support\n",
    "import time\n",
    "quantity_support()\n",
    "from lmfit import Model\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# Script to perform multiple Gaussian/Lorentzian/Voigt fits on the, single/double peak H-alpha line (on the blue, center and red peak)\n",
    "\n",
    "file = np.loadtxt(r\".\\\\GX304-1\\\\smbxgpP201903220040_cr_cg_wr_01.txt\") # smbxgpP201206270016_cr_cg_wr_01.txt smbxgpP201401200077_cr_cg_wr_01.txt smbxgpP202001120152_cr_cg_wr_01.txt\n",
    "Source_Name=\"GX304-1\"\n",
    "x = file[:,0]\n",
    "y = file[:,1]\n",
    "\n",
    "\n",
    "def func_gaus(x, ctr, amp, wid): #Fitting function gaussian\n",
    "    y = np.zeros_like(x)\n",
    "    y = y + amp * np.exp( -((x - ctr)**2/wid**2))\n",
    "    return y\n",
    "def func_DoubleGaus(x, ctr, amp, wid,ctr2,amp2,wid2): #Fitting function gaussian\n",
    "    y = np.zeros_like(x)\n",
    "    y = y + amp * np.exp( -((x - ctr)**2/wid**2)) + amp2 * np.exp( -((x - ctr2)**2/wid2**2))\n",
    "    return y\n",
    "\n",
    "def func_lorentzian(x, ctr, amp, wid): #Fitting function lorentzian\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    y = y + amp * (0.5*wid**2/((x-ctr)**2+(0.5*wid)**2))\n",
    "    return y\n",
    "def func_DoubleLorentzian(x, ctr, amp, wid, ctr2, amp2, wid2): #Fitting function lorentzian\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    y = y + amp * (0.5*wid**2/((x-ctr)**2+(0.5*wid)**2)) + amp2 * (0.5*wid2**2/((x-ctr2)**2+(0.5*wid2)**2))\n",
    "    return y\n",
    "\n",
    "def func_voigt(x, ctr, amp, wid): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid-1\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp\n",
    "    return y\n",
    "def func_DoubleVoigt(x, ctr, amp, wid, ctr2, amp2, wid2): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid-1\n",
    "    gam2 = wid2-1\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp + voigt_profile(x - ctr2, wid2, gam2) * amp2\n",
    "    return y\n",
    "\n",
    "# def find_double_peak_coords(x_data,y_data): #Function to find P_0 guess values for double peak plotting\n",
    "    halpha_region_x = x_data[(x_data > 6540) & (x_data < 6590)]\n",
    "    halpha_region_y = y_data[(x_data > 6540) & (x_data < 6590)]\n",
    "\n",
    "    # print(halpha_region_x)\n",
    "\n",
    "    peaks, props = find_peaks(halpha_region_y)\n",
    "    # print(peaks)\n",
    "    peak_wavelengths=halpha_region_x[peaks]\n",
    "    peak_fluxes=halpha_region_y[peaks]\n",
    "    # print(\"The peak Wl and fluxes: \",peak_wavelengths,peak_fluxes)\n",
    "    \n",
    "    valleys, props = find_peaks(-halpha_region_y)\n",
    "    # print(valleys)\n",
    "    valley_wavelength=halpha_region_x[valleys]\n",
    "    valley_flux=halpha_region_y[valleys]\n",
    "    # print(valley_wavelength,valley_flux)\n",
    "\n",
    "    # --- Step 3: Pick the two largest peaks + the valley between\n",
    "    # Sort peaks by flux\n",
    "    sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "    selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "    # For the dip, just take min flux between the two peaks\n",
    "    left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "    mask = (halpha_region_x > left) & (halpha_region_x < right)\n",
    "    dip_idx = np.argmin(halpha_region_y[mask])\n",
    "    dip_wavelength = halpha_region_x[mask][dip_idx]\n",
    "    dip_flux = halpha_region_y[mask][dip_idx]\n",
    "\n",
    "    # --- Print results ---\n",
    "    print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "    print(\"Dip (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "    ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "    amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "    wid1=6*10\n",
    "    ctr2=valley_wavelength\n",
    "    ctr2=math.trunc(ctr2[0]*10)\n",
    "    wid2=0.5*((valley_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-valley_wavelength))\n",
    "    wid2=math.trunc(3*10)\n",
    "    ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "    amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "    wid3=4*10\n",
    "    amp2=dip_flux\n",
    "    # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "    amp2=math.trunc(amp2*-0.76689539232*10)\n",
    "\n",
    "    result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/8,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "    # result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "\n",
    "    # if len(peaks)==1:\n",
    "    #     # print(peak_wavelengths[0])\n",
    "    #     ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "    #     amp1=math.trunc(peak_fluxes[0]*10)\n",
    "    #     wid1=13.0*10\n",
    "\n",
    "    #     result=[ctr1/10,amp1/10-1,wid1/10]\n",
    "    #     print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def Smooth_find_single_valley_coords(x_data,y_data): #Function to find P_0 guess values for single valley plotting\n",
    "    print(\"We are in the valley finder!\")\n",
    "\n",
    "    valleys, _ = find_peaks(-y_data,distance=3)\n",
    "    print(valleys)\n",
    "    peak_wavelengths=x_data[valleys]\n",
    "    peak_fluxes=y_data[valleys]\n",
    "    if len(valleys)>1:\n",
    "        # Sort peaks by flux\n",
    "        sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "        selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "        # For the valley, just take min flux between the two peaks\n",
    "        left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "        mask = (x_data >= left) & (x_data <= right)\n",
    "        dip_idx = np.argmin(y_data[mask])\n",
    "        dip_wavelength = x_data[mask][dip_idx]\n",
    "        dip_flux = y_data[mask][dip_idx]\n",
    "\n",
    "        print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "        print(\"Valley (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "        ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "        amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "        wid1=6*10\n",
    "        ctr2=dip_wavelength\n",
    "        ctr2=math.trunc(ctr2*10)\n",
    "        wid2=0.3*((dip_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-dip_wavelength))\n",
    "        wid2=math.trunc(3*10)\n",
    "        ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "        amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "        wid3=4*10\n",
    "        amp2=dip_flux\n",
    "        # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "        amp2=math.trunc(amp2*0.76689539232*10)\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/10,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "        # result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "\n",
    "    if len(valleys)==1:\n",
    "        # print(peak_wavelengths[0])\n",
    "        ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "        amp1=math.trunc(peak_fluxes[0]*10)\n",
    "        wid1=5.0*10\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10]\n",
    "    # ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "    # amp1=math.trunc(peak_fluxes[0]*10)\n",
    "    # wid1=5.0*10\n",
    "\n",
    "    # result=[ctr1/10,amp1/10,wid1/10]\n",
    "    # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def Smooth_find_double_peak_coords(x_data,y_data): #Function to find P_0 guess values for double or single peak plotting\n",
    "    halpha_region_x = x_data[(x_data > 6553) & (x_data < 6572)]\n",
    "    halpha_region_y = y_data[(x_data > 6553) & (x_data < 6572)]\n",
    "\n",
    "    halpha_region_y=smooth(halpha_region_y,6)\n",
    "\n",
    "    peaks, _ = find_peaks(halpha_region_y,distance=3)\n",
    "    print(peaks)\n",
    "    peak_wavelengths=halpha_region_x[peaks]\n",
    "    peak_fluxes=halpha_region_y[peaks]\n",
    "\n",
    "    if len(peaks)>1:\n",
    "        # Sort peaks by flux\n",
    "        sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "        selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "        # For the valley, just take min flux between the two peaks\n",
    "        left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "        mask = (halpha_region_x >= left) & (halpha_region_x <= right)\n",
    "        dip_idx = np.argmin(halpha_region_y[mask])\n",
    "        dip_wavelength = halpha_region_x[mask][dip_idx]\n",
    "        dip_flux = halpha_region_y[mask][dip_idx]\n",
    "\n",
    "        # print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "        # print(\"Valley (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "        ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "        amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "        wid1=6*10\n",
    "        ctr2=dip_wavelength\n",
    "        ctr2=math.trunc(ctr2*10)\n",
    "        wid2=0.3*((dip_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-dip_wavelength))\n",
    "        wid2=math.trunc(3*10)\n",
    "        ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "        amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "        wid3=4*10\n",
    "        amp2=dip_flux\n",
    "        # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "        amp2=math.trunc(amp2*0.76689539232*10)\n",
    "\n",
    "        # result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/10,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "        result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "        print(\"3 component guess: \",result)\n",
    "\n",
    "    if len(peaks)==1:\n",
    "        # print(peak_wavelengths[0])\n",
    "        ctr1=math.trunc(peak_wavelengths[0]*10)\n",
    "        amp1=math.trunc(peak_fluxes[0]*10)\n",
    "        wid1=5.0*10\n",
    "\n",
    "        result=[ctr1/10,amp1/10,wid1/10]\n",
    "        print(\"Single peak guess: \",result)\n",
    "\n",
    "    if len(peaks)==0:\n",
    "        result=Smooth_find_single_valley_coords(halpha_region_x,halpha_region_y)\n",
    "        print(\"result found no peaks, maybe only one big valley?\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def spec_normalisation(x,y):\n",
    "\n",
    "\n",
    "    ########### Function to normalise spectrum by dividing with fitted continuum (NTE this should only be done if imported data is not already normalised):\n",
    "    s1_cal=y*u.Unit('erg cm-2 s-2 AA-1') #flux data\n",
    "    wav_cal = x*u.AA #wavelength data\n",
    "\n",
    "    spec=Spectrum1D(spectral_axis=wav_cal,flux=s1_cal)\n",
    "    s_fit=fgc(spec,median_window=1)\n",
    "    y_cont_fitted=s_fit(wav_cal)\n",
    "    print(len(spec.spectral_axis.value))\n",
    "    # print(find_double_peak_coords(spec.spectral_axis.value,(spec.flux/y_cont_fitted).value))\n",
    "\n",
    "\n",
    "    fig=plt.figure(figsize=(8,5)) #create the figure\n",
    "    # plt.yscale(\"log\") #set y scale to log to correctly display the spectra\n",
    "    plt.plot(spec.spectral_axis, spec.flux, label='spectra')\n",
    "    plt.plot(wav_cal, y_cont_fitted, label='fitted continuum')\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    #now plot normalised spectra\n",
    "    fig=plt.figure(figsize=(8,5)) #create the figure\n",
    "\n",
    "    plt.plot(spec.spectral_axis, spec.flux/y_cont_fitted, label='Normalized spectra')\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    # plt.yscale(\"log\") #set y scale to log to correctly display the spectra\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return spec.spectral_axis.value, (spec.flux/y_cont_fitted).value\n",
    "    ###########\n",
    "\n",
    "def fit_ALL_t1(Source_Name, nameString, guess, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_gaus, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_GAUS = func_gaus(x, *popt)\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label='H{alpha}')\n",
    "    plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "    plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_gaus(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_lorentzian, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_LORERTZIAN = func_lorentzian(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Average between GAUS and LORERNTZ fits, plot only:\n",
    "    fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_Average_Gaus_Lor_Fit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    popt, pcov = curve_fit(func_voigt, x, y, p0=guess,maxfev=50000)\n",
    "    fit_VOIGT = func_voigt(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "\n",
    "    \n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_voigt(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "def fit_ALL_t2(Source_Name, nameString, guess, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleGaus, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_GAUS = func_DoubleGaus(x, *popt)\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label='H{alpha}')\n",
    "    plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "    plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_gaus(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleLorentzian, x, y, p0=guess,maxfev=50000)\n",
    "    # print(popt)\n",
    "    fit_LORERTZIAN = func_DoubleLorentzian(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "\n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Average between GAUS and LORERNTZ fits, plot only:\n",
    "    fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_Average_Gaus_Lor_Fit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    popt, pcov = curve_fit(func_DoubleVoigt, x, y, p0=guess,maxfev=50000)\n",
    "    fit_VOIGT = func_DoubleVoigt(x, *popt)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "    plt.grid('minor')\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,max((y[(x > 6553) & (x < 6572)]))+0.2)\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "\n",
    "    \n",
    "    c=1\n",
    "    for i in range(0, len(popt), 3):\n",
    "        y_temp = np.zeros_like(x)\n",
    "        ctr = popt[i]\n",
    "        amp = popt[i+1]\n",
    "        wid = popt[i+2]\n",
    "        y_temp = func_voigt(x, ctr, amp, wid)\n",
    "        plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label=f'individual Component {c}')\n",
    "        c=c+1\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "xmin,xmax = 6550,6575\n",
    "ymin,ymax=-4.5,2\n",
    "graph_W,graph_H = 8,5\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H))\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y,'o')\n",
    "\n",
    "plt.plot(x, smooth(y,3), 'ro', lw=2)\n",
    "\n",
    "plt.plot(x, smooth(y,8), 'go', lw=1.5)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0940bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SCIPY Gaussian, Lorentzian, average between Gaussian and Lorentzian, Voigt fit, in one function with plots\n",
    "###########and saving them as named figures including source name and date observed\n",
    "\n",
    "\n",
    "workdir = pathlib.Path(r\"C:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\")\n",
    "# Image_Dir= str(workdir)+\"\\\\\"+Source_Name\n",
    "Image_Dir= str(workdir)\n",
    "print(Image_Dir)\n",
    "\n",
    "# .glob() produces a generator too\n",
    "workdir.glob(\"*\")\n",
    "\n",
    "\n",
    "spectra_files=list(workdir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "# print ((spectra_files))\n",
    "for i in range(0,len(spectra_files)):\n",
    "    file_Names.append(str(spectra_files[i])[66:])\n",
    "print(\"File names:\",file_Names)\n",
    "\n",
    "\n",
    "guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "print(file)\n",
    "\n",
    "\n",
    "for i in range(0,len(file_Names)):\n",
    "    file = np.loadtxt(str(file_Names[i])) # smbxgpP201206270016_cr_cg_wr_01.txt smbxgpP201401200077_cr_cg_wr_01.txt smbxgpP202001120152_cr_cg_wr_01.txt\n",
    "    Source_Name=\"GX304-1\"\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "    guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    nameString = file_Names[i][15:27] + '_' + Source_Name\n",
    "    print(nameString)\n",
    "    if(len(guess)==3):\n",
    "        fit_ALL_t1(Source_Name, nameString, guess, x, y)\n",
    "    if(len(guess)==6):\n",
    "        fit_ALL_t2(Source_Name, nameString, guess, x, y)\n",
    "    time.sleep(0.1)\n",
    "    # break\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SCIPY Gaussian fitting and plot:\n",
    "# guess = [6555.0, 1.4, 6.0, 6561.0, -1.0, 3.0, 6565.0, 1.6, 4.0]\n",
    "guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "popt, pcov = curve_fit(func_gaus, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_GAUS = func_gaus(x, *popt)\n",
    "\n",
    "########## Error analysis and inclusion in model (can be excluded to go straight to plot):\n",
    "########## Need to find the correct way to get SALT errors on the y data.\n",
    "# yerr_data= np.sqrt((spec.flux/y_cont_fitted).value)\n",
    "# fig=plt.figure(figsize=(16, 9)) #create the figure\n",
    "# plt.xlabel('Wavelength (Angstroms)')\n",
    "# plt.ylabel('Normalised flux')\n",
    "# plt.xlim(6520,6600)\n",
    "# plt.errorbar(spec.spectral_axis.value, (spec.flux/y_cont_fitted).value, yerr_data, ls='', color='k')\n",
    "# plt.scatter(spec.spectral_axis.value, (spec.flux/y_cont_fitted).value, s=7, zorder=1000)\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.grid('minor')\n",
    "\n",
    "plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "plt.plot(x, y, 'r-', linewidth=1,label='Normalised Spectra')\n",
    "plt.plot(x, fit_GAUS, 'b-', linewidth=3, alpha=0.5,label='Gaussian Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_gaus(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "\n",
    "plt.legend(fontsize=Legend_font_size)\n",
    "plt.savefig('Gaussian_demo.png')\n",
    "###########\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SCIPY Lorentzian fitting and plot:\n",
    "# guess = [6555, 1.4, 6.0, 6561.0, -1.1, 3.0, 6565.0, 1.6, 4.0]\n",
    "print(guess)\n",
    "\n",
    "popt, pcov = curve_fit(func_lorentzian, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_LORERTZIAN = func_lorentzian(x, *popt)\n",
    "\n",
    "plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.grid('minor')\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "plt.plot(x, fit_LORERTZIAN , 'b-', linewidth=3, alpha=0.5, label='Lorentzian Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_lorentzian(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "plt.legend(fontsize=Legend_font_size)\n",
    "plt.savefig('Lorentzian_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SCIPY Average between GAUS and LORERNTZ fits, plot only:\n",
    "\n",
    "fit_AVG=(fit_GAUS+fit_LORERTZIAN)/2\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.grid('minor')\n",
    "plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "plt.plot(x, fit_AVG , 'b-', linewidth=3, alpha=0.5,label='average between Gaussian and Lorentzian Fit')\n",
    "plt.legend(fontsize=Legend_font_size)\n",
    "plt.savefig('Average_GAUS_LORENTZ_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53533",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SCIPY Voigt fitting and plot:\n",
    "print(guess)\n",
    "\n",
    "popt, pcov = curve_fit(func_voigt, x, y, p0=guess,maxfev=20000)\n",
    "print(popt)\n",
    "fit_VOIGT = func_voigt(x, *popt)\n",
    "\n",
    "fig=plt.figure(figsize=(graph_W,graph_H)) #create the figure\n",
    "plt.grid('minor')\n",
    "plt.xlabel('Wavelength (Angstroms)')\n",
    "plt.ylabel('Normalised flux')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "plt.plot(x, fit_VOIGT , 'b-', linewidth=3, alpha=0.5,label='Voigt Fit')\n",
    "c=1\n",
    "for i in range(0, len(popt), 3):\n",
    "    y_temp = np.zeros_like(x)\n",
    "    ctr = popt[i]\n",
    "    amp = popt[i+1]\n",
    "    wid = popt[i+2]\n",
    "    y_temp = func_voigt(x, ctr, amp, wid)\n",
    "    plt.plot(x, y_temp, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.5,label=f'individual Component {c}')\n",
    "    c=c+1\n",
    "plt.legend(fontsize=Legend_font_size)\n",
    "plt.savefig('Voigt_demo.png')\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b61330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas python script:\n",
    "from scipy.integrate import quad\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sympy as smp\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#This script calculates the blue and red surface areas and these are compared with the measured equivalent widths\n",
    "#Equations A.17 and A.18\n",
    "\n",
    "file = np.loadtxt('HR_ave_velocities.dat')\n",
    "file2 = np.loadtxt('HR_ave_EW.dat')\n",
    "\n",
    "\n",
    "MJD = file[:,0]\n",
    "#cycles = file[:,1]\n",
    "v_blue = file[:,2]\n",
    "v_red = file[:,3]\n",
    "\n",
    "EW_blue = file2[:,2]\n",
    "EW_red = file2[:,3]\n",
    "\n",
    "MJD_eph = 43366.275\n",
    "\n",
    "\n",
    "def integrand(x,eccen):\n",
    "    return 1.0/((1.0 + eccen*np.cos(x))**2)\n",
    "\n",
    "ep = 0.4\n",
    "\n",
    "#print I[0]\n",
    "\n",
    "a_in = 1.0/(1.0 - ep)\n",
    "inc = 0.52\n",
    "v_crit = 525.0\n",
    "degtorad = np.pi/180.0\n",
    "radtodeg = 180.0/np.pi\n",
    "\n",
    "g = open(\"HR_Areas_ave_out.txt\",\"w\")\n",
    "for i in range(len(MJD)):\n",
    "    t1 = ((2.0*v_crit)/(v_red[i] - v_blue[i]))**2\n",
    "    t2 = ((np.sin(inc))**2)/(1.0 - ep**2)\n",
    "    a_p = t1*t2\n",
    "    ts1 = 0.5*(a_p**2 - a_in**2)*(1.0 - ep**2)*np.cos(inc)\n",
    "    MJD_conv = MJD[i] - 2400000.5\n",
    "    ratio = ((v_red[i]+v_blue[i])/(v_red[i]-v_blue[i]))\n",
    "    om = np.arccos(ratio*(1.0/ep))\n",
    "    cos_om = ratio*(1.0/ep)\n",
    "    f01 = np.arccos(-ep*cos_om) - om\n",
    "    f01_deg = f01*radtodeg\n",
    "    \n",
    "    f02 = (2.0*np.pi - np.arccos(-ep*cos_om)) - om\n",
    "    f02_deg = f02*radtodeg\n",
    "    \n",
    "    \n",
    "    I_b = quad(integrand,f01,f02,args=(ep))\n",
    "    ts2 = I_b[0]\n",
    "    S_blue = ts1*ts2\n",
    "    I_r = quad(integrand,f02,f01+2.0*np.pi,args=(ep))\n",
    "    ts3 = I_r[0]\n",
    "    S_red = ts1*ts3\n",
    "    ratio_areas = S_blue/S_red\n",
    "    ratio_EW = EW_blue[i]/EW_red[i]\n",
    "    g.write(\"%0.3f  %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f   %0.3f\\n\" %(MJD[i],S_blue,S_red,EW_blue[i],EW_red[i],ratio_areas,ratio_EW,I_b[0],I_r[0],f01_deg,f02_deg))\n",
    "g.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#might be useful later to convert degrees to RA coordinates.\n",
    "def map_DEG_to_RA(deg_list):\n",
    "    RA_list=[]\n",
    "    coord=0\n",
    "    for i in range(0,len(deg_list)):\n",
    "        hour= (deg_list[i]//1)*(1/15) #get the integer part of the float degree value and convert to hours. (1/15 hours per degree)\n",
    "        minute= (hour-hour//1)*4.0 #decimal part of the degree float converted to minutes (4 minutes per degree)\n",
    "        second= (minute-minute//1)*60 #decimal part of the minute coordinate, converted to seconds coordinate (60 sec per minute)\n",
    "        coord=hour//1+(minute//1)/100+((second//1)//1)/10000\n",
    "        RA_list.append(coord)\n",
    "    return(RA_list)\n",
    "\n",
    "print(map_DEG_to_RA([22.2565,23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing code\n",
    "x = np.linspace(0,2*np.pi,100)\n",
    "y = np.sin(x) + np.random.random(100) * 0.8\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "plt.plot(x, y,'o')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "plt.plot(x, smooth(y,3), 'r-', lw=2)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "plt.plot(x, smooth(y,19), 'g-', lw=2)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089f6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Main LMFit segment starts here with all imports and some settings\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "import astropy\n",
    "import dateutil.parser\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi']=300 # highres display\n",
    "from lmfit import Model\n",
    "from lmfit.models import GaussianModel\n",
    "from lmfit.models import LorentzianModel\n",
    "from lmfit.models import VoigtModel\n",
    "# from scipy.optimize import curve_fit\n",
    "from scipy.special import voigt_profile\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import quad\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "xmin,xmax = 6520,6600\n",
    "ymin,ymax=-4.5,2\n",
    "graph_W,graph_H = 8+3,5-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd594ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This segment opens the csv database and populates the spectrum filepaths and Julian dates, OVERWRITES THINGS, BE CAREFUL!\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_Name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_Name) #Add the source folder sub directory to save the work to\n",
    "# print(f\"Image saving directory for source {Source_Name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_Name}_dataframe.csv') #read the specific source database csv file\n",
    "# print((f'{Image_Dir}\\{Source_Name}_dataframe.csv'))\n",
    "# print(Source_database)\n",
    "\n",
    "#populate the Spec_Path column with the spectra that are present in the Image_Dir directory:\n",
    "\n",
    "spectra_files=list(Image_Dir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "for i in range(0,len(spectra_files)):\n",
    "    Source_database.loc[i,\"Spec_Path\"]=str(spectra_files[i])[74:] #Save the spectrum txt file path into the Spec_Path column\n",
    "    dt = dateutil.parser.parse(str(spectra_files[i])[81:89]) #Parse the date from the file name string\n",
    "    time = astropy.time.Time(dt) \n",
    "    Source_database.loc[i,\"JD\"]=str(int(time.jd)) #Save into the database as the Julian date for timeseries plots later\n",
    "    file_Names.append(str(spectra_files[i])[74:])\n",
    "print(\"File names:\",Source_database[\"JD\"])\n",
    "\n",
    "Source_database.to_csv(f'{Image_Dir}\\{Source_Name}_dataframe_Updated.csv',index=False) #THIS SAVES AND OVERWRITES WHATEVER VALUES HAVE BEEN READ INTO THE DATABASE! BE CAREFUL WITH IT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe51a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REDUNDANT, MIGHT DELETE THIS CELL!  This segmnent reads from the csv database and analyses the spectra\n",
    "\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_Name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_Name) #Add the source folder sub directory to save the work to\n",
    "# print(f\"Image saving directory for source {Source_Name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_Name}_dataframe.csv') #read the specific source database csv file\n",
    "\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "\n",
    "    p=Source_database[\"Spec_Path\"][i]\n",
    "    print(f\"{Image_Dir}\\{p}\")\n",
    "    file = np.loadtxt(str(f\"{Image_Dir}\\{p}\")) # This imports the wavelength and normalised flux lists from each spectrum file listed in the database\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "\n",
    "    #If statements to determine which kind of fit to do depending on \"type\" or the shape of the Halpha line profile\n",
    "    if(Source_database[\"Type\"][i]==1):\n",
    "        print(\"Single emission peak type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==2):\n",
    "        print(\"Double emission peak type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==3):\n",
    "        print(\"Single absorption valley type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==4):\n",
    "        print(\"Absorption valley walled by emission wings type spectrum\")\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==5):\n",
    "        print(\"Emission peak walled by absorption wings type spectrum\")\n",
    "\n",
    "    # guess = Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    # nameString = file_Names[i][15:27] + '_' + Source_Name\n",
    "    # print(nameString)\n",
    "    # if(len(guess)==3):\n",
    "    #     fit_ALL_t1(Source_Name, nameString, guess, x, y)\n",
    "    # if(len(guess)==6):\n",
    "    #     fit_ALL_t2(Source_Name, nameString, guess, x, y)\n",
    "    time.sleep(0.1)\n",
    "    # break\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb14723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a07de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL THE FUNCTION DEFS\n",
    "\n",
    "printTypeOnGraph=1 #This variable tells the plots to indicate the type of spectrum from 1 to 5 if variable is set to 1.\n",
    "printFWHMOnGraph=0 #This variable tells the plots to show the FWHM per fitted component if variable is set to 1.\n",
    "printHalphaOnGraph=1 #This variable tells the plots to show rest wavelength of H alpha if variable is set to 1.\n",
    "printVtoRratioOnGraph=1 #This variable tells the plots to show the peaks used in V/R calculations and peak seperation if variable is set to 1.\n",
    "printModelUncertaintyOnGraph=1 #This variable tells the plots to show the uncertainty in the model values fitted to the data if variable is set to 1. Set sigma level below\n",
    "ModelUncertaintySigmaLevel = 3 #sigma error level to band-plot if printModelUncertaintyOnGraph variable above is set to 1\n",
    "Legend_font_size=7\n",
    "printEqWOnGraph=1 #show the EqW calculated through numerical integration from the fitted model params or not.\n",
    "\n",
    "\n",
    "\n",
    "def LMFIT_gaussian(x, amp, cen, wid): # as defined in documentation https://lmfit.github.io/lmfit-py/builtin_models.html#gaussianmodel\n",
    "\n",
    "    return (amp / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x-cen)**2 / (2*wid**2))\n",
    "\n",
    "def LMFIT_lorentzian(x, amp, cen, wid): # as defined in documentation https://lmfit.github.io/lmfit-py/builtin_models.html#lorentzianmodel\n",
    "\n",
    "    return ((amp/np.pi)*(wid/((x-cen)**2+wid**2)))\n",
    "\n",
    "#The Voigt model is internally defined for LMfit modules, see https://lmfit.github.io/lmfit-py/builtin_models.html#voigtmodel\n",
    "def func_voigt(x, amp, ctr, wid): #Fitting function voigt\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    gam = wid\n",
    "    y = y + voigt_profile(x - ctr, wid, gam) * amp\n",
    "    return y\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "\n",
    "def Smooth_find_single_valley_coords(x_data,y_data): #Function to find the wavelength coordinate of a single valley\n",
    "    print(\"We are in the valley finder!\")\n",
    "\n",
    "    halpha_region_x = x_data[(x_data >= 6553) & (x_data <= 6575)]\n",
    "    halpha_region_y = y_data[(x_data >= 6553) & (x_data <= 6575)]\n",
    "\n",
    "    halpha_region_y=smooth(halpha_region_y,6)\n",
    "\n",
    "    dip_idx = np.argmin(halpha_region_y[(halpha_region_x >= 6553) & (halpha_region_x <= 6572)])\n",
    "    dip_wavelength = halpha_region_x[(halpha_region_x >= 6553) & (halpha_region_x <= 6572)][dip_idx]\n",
    "\n",
    "    return dip_wavelength\n",
    "\n",
    "def Smooth_find_single_peak_coords(x_data,y_data): #Function to find the wavelength coordinate of a single peak\n",
    "    halpha_region_x = x_data[(x_data >= 6553) & (x_data <= 6575)]\n",
    "    halpha_region_y = y_data[(x_data >= 6553) & (x_data <= 6575)]\n",
    "\n",
    "    halpha_region_y=smooth(halpha_region_y,6)\n",
    "\n",
    "    peak_idx = np.argmax(halpha_region_y[(halpha_region_x >= 6553) & (halpha_region_x <= 6572)])\n",
    "    peak_wavelength = halpha_region_x[(halpha_region_x >= 6553) & (halpha_region_x <= 6572)][peak_idx]\n",
    "\n",
    "    return peak_wavelength\n",
    "\n",
    "def Smooth_find_double_peak_coords(x_data,y_data): #Function to find P_0 guess values for double peak plotting\n",
    "    halpha_region_x = x_data[(x_data > 6553) & (x_data < 6575)]\n",
    "    halpha_region_y = y_data[(x_data > 6553) & (x_data < 6575)]\n",
    "\n",
    "    halpha_region_y=smooth(halpha_region_y,3)\n",
    "\n",
    "    peaks, _ = find_peaks(halpha_region_y,distance=2)\n",
    "    print(peaks)\n",
    "    peak_wavelengths=halpha_region_x[peaks]\n",
    "    peak_fluxes=halpha_region_y[peaks]\n",
    "\n",
    "    if len(peaks)>1:\n",
    "        # Sort peaks by flux\n",
    "        sorted_peaks = np.argsort(peak_fluxes)[-2:]  # take top 2\n",
    "        selected_peaks = [(peak_wavelengths[i], peak_fluxes[i]) for i in sorted_peaks]\n",
    "\n",
    "        # For the valley, just take min flux between the two peaks\n",
    "        left, right = np.min([p[0] for p in selected_peaks]), np.max([p[0] for p in selected_peaks])\n",
    "        mask = (halpha_region_x >= left) & (halpha_region_x <= right)\n",
    "        dip_idx = np.argmin(halpha_region_y[mask])\n",
    "        dip_wavelength = halpha_region_x[mask][dip_idx] #This is basically the location of the centroid?\n",
    "        dip_flux = halpha_region_y[mask][dip_idx]\n",
    "\n",
    "        # print(\"Peaks (λ, flux):\", selected_peaks)\n",
    "        # print(\"Valley (λ, flux):\", (dip_wavelength, dip_flux))\n",
    "\n",
    "        ctr1=math.trunc(selected_peaks[0][0]*10)\n",
    "        amp1=math.trunc(selected_peaks[0][1]*10)\n",
    "        wid1=6*10\n",
    "        ctr2=dip_wavelength\n",
    "        ctr2=math.trunc(ctr2*10)\n",
    "        wid2=0.3*((dip_wavelength-peak_wavelengths[0])+(peak_wavelengths[1]-dip_wavelength))\n",
    "        wid2=math.trunc(3*10)\n",
    "        ctr3=math.trunc(selected_peaks[1][0]*10)\n",
    "        amp3=math.trunc(selected_peaks[1][1]*10)\n",
    "        wid3=4*10\n",
    "        amp2=dip_flux\n",
    "        # amp2=-((amp1/10+amp3/10)/2-amp2)*5\n",
    "        amp2=math.trunc(amp2*0.76689539232*10)\n",
    "\n",
    "        # result=[ctr1/10,amp1/10,wid1/10,ctr2/10,amp2/10,wid2/10,ctr3/10,amp3/10,wid3/10]\n",
    "        result=[ctr1/10,amp1/10-1,wid1/10,ctr3/10,amp3/10-1,wid3/10]\n",
    "        print(\"2 component guess: \",result[0],result[3])\n",
    "\n",
    "    if (len(peaks)>2 | len(peaks)<1):\n",
    "        print(\"Something went wrong in peak finiding\")\n",
    "        result=\"something went wrong\"\n",
    "        \n",
    "\n",
    "    return [result[0],result[3]] #returns blue peak central wavelength, then red peak central wavelength\n",
    "\n",
    "\n",
    "def LMFIT_t1_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 1 spectra with single emission peak\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the single peak gaussian component\n",
    "\n",
    "    model = gmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=8, min=0, max=12)\n",
    "    params['g1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['g1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['g1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Gaussian Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T1\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Gaus_Integration(result.params['g1_amplitude'].value,result.params['g1_center'].value,result.params['g1_sigma'].value,result.params['g1_height'].value)\n",
    "        print(EqWidPlot[0])\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "def LMFIT_t1_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 1 spectra with single emission peak\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the single peak lorentzian component\n",
    "\n",
    "    model = lmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=8, min=0, max=10.12)\n",
    "    params['l1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['l1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['l1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Lorentzian Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T1\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Lor_Integration(result.params['l1_amplitude'].value,result.params['l1_center'].value,result.params['l1_sigma'].value,result.params['l1_height'].value)\n",
    "        print(EqWidPlot[0])\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "def LMFIT_t1_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 1 spectra with single emission peak\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the single peak voigt component\n",
    "\n",
    "    model = vmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=8, min=0, max=12)\n",
    "    params['v1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['v1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['v1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Voigt Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T1\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Voigt_Integration(result.params['v1_amplitude'].value,result.params['v1_center'].value,result.params['v1_sigma'].value,result.params['v1_height'].value)\n",
    "        print(EqWidPlot[0])\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "\n",
    "def LMFIT_t2_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 2 spectra with double emission peak\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the first peak gaussian component\n",
    "    gmodel2 = GaussianModel(prefix='g2_') # Define the second peak gaussian component\n",
    "\n",
    "    model = gmodel1 + gmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=8, min=1, max=12)\n",
    "    params['g1_center'].set(value=centroid_guess[0], min=centroid_guess[0]-2, max=centroid_guess[0]+2)\n",
    "    params['g1_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['g2_amplitude'].set(value=8, min=1, max=12)\n",
    "    params['g2_center'].set(value=centroid_guess[1], min=centroid_guess[1]-2, max=centroid_guess[1]+2)\n",
    "    params['g2_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['g1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_gaussian(x, result.params['g1_amplitude'].value, result.params['g1_center'].value, result.params['g1_sigma'].value)\n",
    "    result2= LMFIT_gaussian(x, result.params['g2_amplitude'].value, result.params['g2_center'].value, result.params['g2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Gaussian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T2\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printVtoRratioOnGraph==1):\n",
    "        x_temp1= result.params['g1_center'].value\n",
    "        y_temp1= max(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        idx = np.argmax(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        x_temp1 = x[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)][idx]\n",
    "        plt.axvline(x = x_temp1, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp1, y_temp1, color = 'black', linewidth=2)\n",
    "        x_temp2= result.params['g2_center'].value\n",
    "        y_temp2= max(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        idx = np.argmax(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        x_temp2 = x[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)][idx]\n",
    "        plt.axvline(x = x_temp2, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp2, y_temp2, color = 'black', linewidth=2, label=f\"V/R {np.round(y_temp1/y_temp2,3)} Peaksep {np.round(x_temp2-x_temp1,3)}\")\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    \n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,\n",
    "            result.params['g2_height'].value, result.params['g2_center'].value, result.params['g2_sigma'].value,\n",
    "            np.round(y_temp1/y_temp2,3), np.round(x_temp2-x_temp1,3)]#parameters of 2 components, and V/R with peak seperation value\n",
    "\n",
    "def LMFIT_t2_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 2 spectra with double emission peak\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the first peak Lorentzian component\n",
    "    lmodel2 = LorentzianModel(prefix='l2_') # Define the second peak Lorentzian component\n",
    "\n",
    "    model = lmodel1 + lmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['l1_amplitude'].set(value=8, min=1, max=10.12)\n",
    "    params['l1_center'].set(value=centroid_guess[0], min=centroid_guess[0]-2, max=centroid_guess[0]+2)\n",
    "    params['l1_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['l2_amplitude'].set(value=8, min=1, max=12)\n",
    "    params['l2_center'].set(value=centroid_guess[1], min=centroid_guess[1]-2, max=centroid_guess[1]+2)\n",
    "    params['l2_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_lorentzian(x, result.params['l1_amplitude'].value, result.params['l1_center'].value, result.params['l1_sigma'].value)\n",
    "    result2= LMFIT_lorentzian(x, result.params['l2_amplitude'].value, result.params['l2_center'].value, result.params['l2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Lorentzian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T2\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printVtoRratioOnGraph==1):\n",
    "        x_temp1= result.params['l1_center'].value\n",
    "        y_temp1= max(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        idx = np.argmax(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        x_temp1 = x[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)][idx]\n",
    "        plt.axvline(x = x_temp1, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp1, y_temp1, color = 'black', linewidth=2)\n",
    "        x_temp2= result.params['l2_center'].value\n",
    "        y_temp2= max(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        idx = np.argmax(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        x_temp2 = x[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)][idx]\n",
    "        plt.axvline(x = x_temp2, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp2, y_temp2, color = 'black', linewidth=2, label=f\"V/R {np.round(y_temp1/y_temp2,3)} Peaksep {np.round(x_temp2-x_temp1,3)}\")\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,\n",
    "            result.params['l2_height'].value, result.params['l2_center'].value, result.params['l2_sigma'].value,\n",
    "            np.round(y_temp1/y_temp2,3), np.round(x_temp2-x_temp1,3)]#parameters of 2 components, and V/R with peak seperation value]\n",
    "\n",
    "def LMFIT_t2_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 2 spectra with double emission peak\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the first peak Voigt component\n",
    "    vmodel2 = VoigtModel(prefix='v2_') # Define the second peak Voigt component\n",
    "\n",
    "    model = vmodel1 + vmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_double_peak_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['v1_amplitude'].set(value=8, min=1, max=12)\n",
    "    params['v1_center'].set(value=centroid_guess[0], min=centroid_guess[0]-2, max=centroid_guess[0]+2)\n",
    "    params['v1_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['v2_amplitude'].set(value=8, min=1, max=12)\n",
    "    params['v2_center'].set(value=centroid_guess[1], min=centroid_guess[1]-2, max=centroid_guess[1]+2)\n",
    "    params['v2_sigma'].set(value=3, min=0, max=7)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= func_voigt(x, result.params['v1_amplitude'].value, result.params['v1_center'].value, result.params['v1_sigma'].value)\n",
    "    result2= func_voigt(x, result.params['v2_amplitude'].value, result.params['v2_center'].value, result.params['v2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Voigt best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T2\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printVtoRratioOnGraph==1):\n",
    "        x_temp1= result.params['v1_center'].value\n",
    "        y_temp1= max(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        idx = np.argmax(result1[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)])\n",
    "        x_temp1 = x[(x >= x_temp1-1.5) & (x <= x_temp1+1.5)][idx]\n",
    "        plt.axvline(x = x_temp1, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp1, y_temp1, color = 'black', linewidth=2)\n",
    "        x_temp2= result.params['v2_center'].value\n",
    "        y_temp2= max(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        idx = np.argmax(result2[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)])\n",
    "        x_temp2 = x[(x >= x_temp2-1.5) & (x <= x_temp2+1.5)][idx]\n",
    "        plt.axvline(x = x_temp2, color = 'black', linewidth=0.5)\n",
    "        plt.scatter(x_temp2, y_temp2, color = 'black', linewidth=2, label=f\"V/R {np.round(y_temp1/y_temp2,3)} Peaksep {np.round(x_temp2-x_temp1,3)}\")\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,\n",
    "            result.params['v2_height'].value, result.params['v2_center'].value, result.params['v2_sigma'].value,\n",
    "            np.round(y_temp1/y_temp2,3), np.round(x_temp2-x_temp1,3)]#parameters of 2 components, and V/R [6] with peak seperation [7] value]\n",
    "\n",
    "\n",
    "def LMFIT_t3_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the single valley gaussian component\n",
    "\n",
    "    model = gmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_valley_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=-2, max=-0.5, min=-35)\n",
    "    params['g1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['g1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['g1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Gaussian Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T3\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Gaus_Integration(result.params['g1_amplitude'].value,result.params['g1_center'].value,result.params['g1_sigma'].value,result.params['g1_height'].value)\n",
    "        print(EqWidPlot[0])\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "def LMFIT_t3_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the single valley lorentzian component\n",
    "\n",
    "    model = lmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_valley_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['l1_amplitude'].set(value=-2, max=-0.5, min=-35)\n",
    "    params['l1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['l1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['l1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Lorentzian Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T3\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Lor_Integration(result.params['l1_amplitude'].value,result.params['l1_center'].value,result.params['l1_sigma'].value,result.params['l1_height'].value)\n",
    "        print(EqWidPlot[0])\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "def LMFIT_t3_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 3 spectra with single absorption valley\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the single valley voigt component\n",
    "\n",
    "    model = vmodel1 # This is redundant, but only done for consistancy with multi component fits\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    centroid_guess=Smooth_find_single_valley_coords(x,y)\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['v1_amplitude'].set(value=-2, max=-0.5, min=-35)\n",
    "    params['v1_center'].set(value=centroid_guess, min=centroid_guess-2, max=centroid_guess+2)\n",
    "    params['v1_sigma'].set(value=10, min=0)\n",
    "    \n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "\n",
    "    print(result.params['v1_height'].value) \n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Voigt Fit')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T3\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    if (printEqWOnGraph==1):\n",
    "        EqWidPlot=EW_Voigt_Integration(result.params['v1_amplitude'].value,result.params['v1_center'].value,result.params['v1_sigma'].value,result.params['v1_height'].value)\n",
    "        print(round(EqWidPlot[0],3))\n",
    "        plt.fill_betweenx([min(min(EqWidPlot[2][:])),max(max(EqWidPlot[2][:]))],EqWidPlot[3],EqWidPlot[4], alpha=0.05,color=\"black\")\n",
    "        plt.scatter([EqWidPlot[3],EqWidPlot[4],EqWidPlot[4],EqWidPlot[3]],[EqWidPlot[5],EqWidPlot[5],0,0], s=2, color=\"crimson\",label=rf\"EW= {round(EqWidPlot[0],3)} $\\AA$\")\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,round(EqWidPlot[0],3)]\n",
    "\n",
    "\n",
    "def LMFIT_t4_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 4 spectra with an absorption valley, winged by emission\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the first peak gaussian component\n",
    "    gmodel2 = GaussianModel(prefix='g2_') # Define the second peak gaussian component\n",
    "\n",
    "    model = gmodel1 + gmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['g1_center'].set(value=6563, min=6558, max=6566)\n",
    "    params['g1_sigma'].set(value=6, min=0, max=8)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['g2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['g2_center'].set(value=6563, min=6550, max=6570)\n",
    "    params['g2_sigma'].set(value=9, min=0, max=15)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['g1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_gaussian(x, result.params['g1_amplitude'].value, result.params['g1_center'].value, result.params['g1_sigma'].value)\n",
    "    result2= LMFIT_gaussian(x, result.params['g2_amplitude'].value, result.params['g2_center'].value, result.params['g2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    # plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Gaussian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T4\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,\n",
    "            result.params['g2_height'].value, result.params['g2_center'].value, result.params['g2_sigma'].value]\n",
    "\n",
    "def LMFIT_t4_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 4 spectra with an absorption valley, winged by emission\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the first peak Lorentzian component\n",
    "    lmodel2 = LorentzianModel(prefix='l2_') # Define the second peak Lorentzian component\n",
    "\n",
    "    model = lmodel1 + lmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['l1_center'].set(value=6563, min=6558, max=6566)\n",
    "    params['l1_sigma'].set(value=6, min=0, max=8)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['l2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['l2_center'].set(value=6563, min=6550, max=6570)\n",
    "    params['l2_sigma'].set(value=9, min=0, max=15)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_lorentzian(x, result.params['l1_amplitude'].value, result.params['l1_center'].value, result.params['l1_sigma'].value)\n",
    "    result2= LMFIT_lorentzian(x, result.params['l2_amplitude'].value, result.params['l2_center'].value, result.params['l2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Lorentzian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T4\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,\n",
    "            result.params['l2_height'].value, result.params['l2_center'].value, result.params['l2_sigma'].value]\n",
    "\n",
    "def LMFIT_t4_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 4 spectra with an absorption valley, winged by emission\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the first peak Voigt component\n",
    "    vmodel2 = VoigtModel(prefix='v2_') # Define the second peak Voigt component\n",
    "\n",
    "    model = vmodel1 + vmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['v1_center'].set(value=6563, min=6558, max=6566)\n",
    "    params['v1_sigma'].set(value=6, min=0, max=8)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['v2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['v2_center'].set(value=6563, min=6550, max=6570)\n",
    "    params['v2_sigma'].set(value=9, min=0, max=15)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= func_voigt(x, result.params['v1_amplitude'].value, result.params['v1_center'].value, result.params['v1_sigma'].value)\n",
    "    result2= func_voigt(x, result.params['v2_amplitude'].value, result.params['v2_center'].value, result.params['v2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Voigt best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T4\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,\n",
    "            result.params['v2_height'].value, result.params['v2_center'].value, result.params['v2_sigma'].value]\n",
    "\n",
    "\n",
    "def LMFIT_t5_G(Source_Name,nameString,x,y): # Fit Gaussian function for the type 5 spectra with an emission peak, winged by absorption\n",
    "\n",
    "    gmodel1 = GaussianModel(prefix='g1_') # Define the first peak gaussian component\n",
    "    gmodel2 = GaussianModel(prefix='g2_') # Define the second peak gaussian component\n",
    "\n",
    "    model = gmodel1 + gmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Gaussian\n",
    "    params['g1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['g1_center'].set(value=6563, min=6558, max=6570)\n",
    "    params['g1_sigma'].set(value=9, min=8, max=15)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['g2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['g2_center'].set(value=6563, min=6555, max=6570)\n",
    "    params['g2_sigma'].set(value=3, min=0, max=5)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['g1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_gaussian(x, result.params['g1_amplitude'].value, result.params['g1_center'].value, result.params['g1_sigma'].value)\n",
    "    result2= LMFIT_gaussian(x, result.params['g2_amplitude'].value, result.params['g2_center'].value, result.params['g2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    # plt.ylim(min(y[(x > 6553) & (x < 6572)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Gaussian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T5\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_GaussianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['g1_height'].value, result.params['g1_center'].value, result.params['g1_sigma'].value,\n",
    "            result.params['g2_height'].value, result.params['g2_center'].value, result.params['g2_sigma'].value]\n",
    "\n",
    "def LMFIT_t5_L(Source_Name,nameString,x,y): # Fit Lorentzian function for the type 5 spectra with an emission peak, winged by absorption\n",
    "\n",
    "    lmodel1 = LorentzianModel(prefix='l1_') # Define the first peak Lorentzian component\n",
    "    lmodel2 = LorentzianModel(prefix='l2_') # Define the second peak Lorentzian component\n",
    "\n",
    "    model = lmodel1 + lmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Lorentzian\n",
    "    params['l1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['l1_center'].set(value=6563, min=6558, max=6570)\n",
    "    params['l1_sigma'].set(value=9, min=8, max=15)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['l2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['l2_center'].set(value=6563, min=6555, max=6570)\n",
    "    params['l2_sigma'].set(value=3, min=0, max=5)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= LMFIT_lorentzian(x, result.params['l1_amplitude'].value, result.params['l1_center'].value, result.params['l1_sigma'].value)\n",
    "    result2= LMFIT_lorentzian(x, result.params['l2_amplitude'].value, result.params['l2_center'].value, result.params['l2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Lorentzian best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T5\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_LorentzianFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['l1_height'].value, result.params['l1_center'].value, result.params['l1_sigma'].value,\n",
    "            result.params['l2_height'].value, result.params['l2_center'].value, result.params['l2_sigma'].value]\n",
    "\n",
    "def LMFIT_t5_V(Source_Name,nameString,x,y): # Fit Voigt function for the type 5 spectra with an emission peak, winged by absorption\n",
    "\n",
    "    vmodel1 = VoigtModel(prefix='v1_') # Define the first peak Voigt component\n",
    "    vmodel2 = VoigtModel(prefix='v2_') # Define the second peak Voigt component\n",
    "\n",
    "    model = vmodel1 + vmodel2  # Combine them into a composite model\n",
    "\n",
    "    params = model.make_params() # Set up initial parameters and perform the fit\n",
    "\n",
    "    # Set initial guesses for the first Voigt\n",
    "    params['v1_amplitude'].set(value=-40, max=0, min=-200)\n",
    "    params['v1_center'].set(value=6563, min=6558, max=6570)\n",
    "    params['v1_sigma'].set(value=9, min=8, max=15)\n",
    "\n",
    "    # Set initial guesses for the second Gaussian\n",
    "    params['v2_amplitude'].set(value=20, min=0, max = 50)\n",
    "    params['v2_center'].set(value=6563, min=6555, max=6570)\n",
    "    params['v2_sigma'].set(value=3, min=0, max=5)\n",
    "\n",
    "    result = model.fit(y, params, x=x, max_nfev=10000) # Perform the fit\n",
    "    # print(result.params['l1_amplitude'].value)\n",
    "\n",
    "    print(result.fit_report()) # Print results report to see how good the fitting went\n",
    "\n",
    "    result1= func_voigt(x, result.params['v1_amplitude'].value, result.params['v1_center'].value, result.params['v1_sigma'].value)\n",
    "    result2= func_voigt(x, result.params['v2_amplitude'].value, result.params['v2_center'].value, result.params['v2_sigma'].value)\n",
    "\n",
    "    plt.figure(figsize=(graph_W,graph_H)) # create the figure\n",
    "    plt.xlabel('Wavelength (Angstroms)')\n",
    "    plt.ylabel('Normalised flux')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(min(y[(x > xmin) & (x < xmax)])-0.2,1.2)\n",
    "    plt.grid('minor')\n",
    "    plt.plot(x, y, 'r--', linewidth=1, label=\"SALT data\")\n",
    "    plt.plot(x, result.best_fit , 'b-', linewidth=2, alpha=0.5,label='Voigt best fit')\n",
    "    plt.plot(x, result1, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 1')\n",
    "    plt.plot(x, result2, color=(random.random(), random.random(), random.random()), linewidth=3, alpha=0.3,label='individual Component 2')\n",
    "    if (printTypeOnGraph==1):\n",
    "        plt.title(\"T5\")\n",
    "    if (printHalphaOnGraph==1):\n",
    "        plt.axvline(x = 6562.8, color = 'orange', linewidth=3, alpha=0.2, label=r'H$\\alpha$')\n",
    "    if (printModelUncertaintyOnGraph==1):\n",
    "        dely = result.eval_uncertainty(sigma=ModelUncertaintySigmaLevel)\n",
    "        plt.fill_between(x, result.best_fit-dely, result.best_fit+dely, color=\"#ABABAB\",\n",
    "                 label=rf'{ModelUncertaintySigmaLevel}-$\\sigma$ uncertainty band', alpha=0.5)\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\'+ nameString + '_VoigtFit.png')\n",
    "    plt.close()\n",
    "\n",
    "    return [result.params['v1_height'].value, result.params['v1_center'].value, result.params['v1_sigma'].value,\n",
    "            result.params['v2_height'].value, result.params['v2_center'].value, result.params['v2_sigma'].value]\n",
    "\n",
    "\n",
    "#These all do what their names say. The fit all 3 types of functions depending on the type specified in the database, and save the figures in the working directory\n",
    "def LMfit_ALL_t1(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t1_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t1_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t1_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "def LMfit_ALL_t2(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    fit_all_t2_G = LMFIT_t2_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    fit_all_t2_L = LMFIT_t2_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    fit_all_t2_V = LMFIT_t2_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "    return(fit_all_t2_G,fit_all_t2_L,fit_all_t2_V)\n",
    "\n",
    "def LMfit_ALL_t3(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t3_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t3_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t3_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "def LMfit_ALL_t4(Source_Name, nameString, x, y):\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t4_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t4_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t4_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "def LMfit_ALL_t5(Source_Name, nameString, x, y):\n",
    "\n",
    "\n",
    "    ########### Gaussian fitting and plot:\n",
    "    LMFIT_t5_G(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Lorentzian fitting and plot:\n",
    "    LMFIT_t5_L(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "\n",
    "    ########### Voigt fitting and plot:\n",
    "    LMFIT_t5_V(Source_Name,nameString,x,y)\n",
    "    ###########\n",
    "    \n",
    "    return (\"finished \"+nameString)\n",
    "\n",
    "\n",
    "def plot_Time_Series_Data(x,y,y_axis_label):\n",
    "\n",
    "    plt.figure(figsize=(graph_W+3,graph_H-1)) # create the figure\n",
    "    plt.xlabel('Time (JD)')\n",
    "    plt.ylabel(f'{y_axis_label}')\n",
    "    plt.grid('minor')\n",
    "    x_plotted=[]\n",
    "    y_plotted=[]\n",
    "    for i in range(0,len(x)):\n",
    "        if y!=np.nan:\n",
    "            x_plotted.append(x[i])\n",
    "            y_plotted.append(y[i])\n",
    "        if y==np.nan:\n",
    "            x_plotted.append(x[i])\n",
    "            y_plotted.append(0)\n",
    "        print(x_plotted[i], y_plotted[i])\n",
    "    plt.scatter(x_plotted, y_plotted, label=rf\"{y_axis_label}\")\n",
    "    plt.ticklabel_format(style='plain')\n",
    "    plt.legend(fontsize=Legend_font_size)\n",
    "    plt.savefig('.\\\\'+ Source_Name +'\\\\' + rf'T2_Time_series_{y_axis_label}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def EW_Gaus_Integration(a,c,b,height):\n",
    "    f = lambda x: a/(b * np.sqrt(2 * np.pi)) * np.exp(-(x-c)**2/(2 * b**2))\n",
    "    FULL_integral = quad(f, 6400, 6700)[0] #this is the full value if the fitted function is integrated\n",
    "\n",
    "    step_size = 0.00001 #step size with which the rectangle width is increased until that rectangle has the same area as the full integral\n",
    "    delta = 0 # Place holder variables up to PART_integral, this one is for the size of the move away from the centre\n",
    "    left = 0 # The left point where the EW measurement is taken \n",
    "    right = 0 # The right point where the EW measurement is taken\n",
    "    PART_integral = 0 #Area of the rectangle used to find EW\n",
    "\n",
    "    if(height>0):\n",
    "        while(PART_integral<=FULL_integral):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    if(height<0):\n",
    "        while(PART_integral>=FULL_integral):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    EqW = right-left\n",
    "    print(f\"Equivalent width is: {round(EqW,3)}\")\n",
    "\n",
    "    xvals=np.linspace(6500,6600,1000)\n",
    "    yvals=[]\n",
    "    yvals.append(LMFIT_gaussian(xvals,a,c,b))\n",
    "\n",
    "    return([EqW,xvals,yvals,left,right,height])\n",
    "\n",
    "def EW_Lor_Integration(a,c,b,height):\n",
    "    f = lambda x: a/(np.pi) * (b/((x-c)**2+b**2))\n",
    "    FULL_integral = quad(f, 6400, 6700)[0] #this is the full value if the fitted function is integrated\n",
    "\n",
    "    step_size = 0.00001 #step size with which the rectangle width is increased until that rectangle has the same area as the full integral\n",
    "    delta = 0 # Place holder variables up to PART_integral, this one is for the size of the move away from the centre\n",
    "    left = 0 # The left point where the EW measurement is taken \n",
    "    right = 0 # The right point where the EW measurement is taken\n",
    "    PART_integral = 0 #Area of the rectangle used to find EW\n",
    "\n",
    "    if(height>0):\n",
    "        while(PART_integral<=FULL_integral):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    if(height<0):\n",
    "        while(PART_integral>=FULL_integral):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    EqW = right-left\n",
    "    print(f\"Equivalent width is: {round(EqW,3)}\")\n",
    "\n",
    "    xvals=np.linspace(6500,6600,1000)\n",
    "    yvals=[]\n",
    "    yvals.append(LMFIT_lorentzian(xvals,a,c,b))\n",
    "\n",
    "    return([EqW,xvals,yvals,left,right,height])\n",
    "\n",
    "def EW_Voigt_Integration(a,c,b,height):\n",
    "\n",
    "    xvals=np.linspace(6500,6600,1000)\n",
    "    yvals=[]\n",
    "    yvals.append(func_voigt(xvals, a, c, b))\n",
    "    FULL_integral = cumulative_trapezoid(yvals, xvals, initial=0) #this is the full value if the fitted function is integrated\n",
    "    step_size = 0.00001 #step size with which the rectangle width is increased until that rectangle has the same area as the full integral\n",
    "    delta = 0 # Place holder variables up to PART_integral, this one is for the size of the move away from the centre\n",
    "    left = 0 # The left point where the EW measurement is taken \n",
    "    right = 0 # The right point where the EW measurement is taken\n",
    "    PART_integral = 0 #Area of the rectangle used to find EW\n",
    "\n",
    "    while(PART_integral<=(FULL_integral[-1])[-1]):\n",
    "        delta = delta+step_size\n",
    "        left = c - delta\n",
    "        right= c + delta\n",
    "        PART_integral = height * (2*delta)\n",
    "\n",
    "    if(height>0):\n",
    "        while(PART_integral<=(FULL_integral[-1])[-1]):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    if(height<0):\n",
    "        while(PART_integral>=(FULL_integral[-1])[-1]):\n",
    "            delta = delta+step_size\n",
    "            left = c - delta\n",
    "            right= c + delta\n",
    "            PART_integral = height * (2*delta)\n",
    "    EqW = right-left\n",
    "    print(f\"Equivalent width is: {round(EqW,3)}\")\n",
    "    \n",
    "    EqW = right-left\n",
    "    print(f\"Equivalent width is: {round(EqW,3)}\")\n",
    "\n",
    "    return([EqW,xvals,yvals,left,right,height])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd1ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial work directory:  c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\n",
      "File names: ['GX304-1\\\\smbxgpP201206270016_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201206270017_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201301240111_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201301240112_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303060077_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303060078_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303230069_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201303230070_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201304270055_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201304270056_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201401200076_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201401200077_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402160001_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402160002_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402270028_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201402270029_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403100009_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403100010_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403220152_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201403220153_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404050094_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404050095_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404160072_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201404160073_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405030027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405030028_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405110039_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405110040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405140003_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405140004_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405170012_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405170013_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405310014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201405310015_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406100025_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406100026_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201406130030_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501150046_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501150047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501200020_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201501200021_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502030011_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502030012_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502110013_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502110014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502190017_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502190018_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502250026_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201502250027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606010027_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606170033_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606180053_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606240033_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201606290014_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201701250174_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201702150044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201703140037_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201703310052_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201704130054_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201706050039_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201707010034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201707110044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201801160059_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201805230058_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201806250047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201901270047_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902060059_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902160083_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201902260045_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201903110041_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP201903220040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202001120152_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202003180084_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202006030040_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202007010055_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202007280246_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202204010106_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202204010107_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202206190042_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202206190043_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207130034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207130035_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207270043_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202207270044_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202208040034_cr_cg_wr_01.txt', 'GX304-1\\\\smbxgpP202208040035_cr_cg_wr_01.txt']\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201206270016_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201206270017_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201301240111_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201301240112_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303060077_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303060078_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303230069_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201303230070_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201304270055_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201304270056_cr_cg_wr_01.txt\n",
      "Single emission peak type spectrum\n",
      "c:\\Users\\debee\\Downloads\\git\\IR_Variability_Of_BeXRBs_PhD\\Scripts\\GX304-1\\smbxgpP201401200076_cr_cg_wr_01.txt\n",
      "Double emission peak type spectrum\n",
      "[23 40]\n",
      "2 component guess:  6558.9 6563.3\n",
      "[[Model]]\n",
      "    (Model(gaussian, prefix='g1_') + Model(gaussian, prefix='g2_'))\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 107\n",
      "    # data points      = 3170\n",
      "    # variables        = 6\n",
      "    chi-square         = 3.11873397\n",
      "    reduced chi-square = 9.8569e-04\n",
      "    Akaike info crit   = -21937.2693\n",
      "    Bayesian info crit = -21900.9004\n",
      "    R-squared          = 0.88865710\n",
      "[[Variables]]\n",
      "    g1_amplitude:  2.55899077 +/- 2.05290992 (80.22%) (init = 8)\n",
      "    g1_center:     6556.90000 +/- 4.73667780 (0.07%) (init = 6558.9)\n",
      "    g1_sigma:      7.00000000 +/- 2.60619426 (37.23%) (init = 3)\n",
      "    g2_amplitude:  8.71345739 +/- 2.02238981 (23.21%) (init = 8)\n",
      "    g2_center:     6562.97609 +/- 0.14652355 (0.00%) (init = 6563.3)\n",
      "    g2_sigma:      4.64647140 +/- 0.25878446 (5.57%) (init = 3)\n",
      "    g1_fwhm:       16.4837400 +/- 6.13711836 (37.23%) == '2.3548200*g1_sigma'\n",
      "    g1_height:     0.14584138 +/- 0.07249815 (49.71%) == '0.3989423*g1_amplitude/max(1e-15, g1_sigma)'\n",
      "    g2_fwhm:       10.9416038 +/- 0.60939082 (5.57%) == '2.3548200*g2_sigma'\n",
      "    g2_height:     0.74813045 +/- 0.13317254 (17.80%) == '0.3989423*g2_amplitude/max(1e-15, g2_sigma)'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(g1_amplitude, g2_amplitude) = -0.9988\n",
      "    C(g1_amplitude, g1_center)    = +0.9945\n",
      "    C(g1_center, g2_amplitude)    = -0.9944\n",
      "    C(g2_amplitude, g2_sigma)     = +0.9780\n",
      "    C(g1_amplitude, g2_sigma)     = -0.9742\n",
      "    C(g1_center, g2_sigma)        = -0.9579\n",
      "    C(g1_center, g1_sigma)        = +0.9109\n",
      "    C(g1_amplitude, g1_sigma)     = +0.8957\n",
      "    C(g1_sigma, g2_amplitude)     = -0.8855\n",
      "    C(g1_sigma, g2_sigma)         = -0.8252\n",
      "    C(g2_center, g2_sigma)        = -0.6229\n",
      "    C(g2_amplitude, g2_center)    = -0.5574\n",
      "    C(g1_amplitude, g2_center)    = +0.5462\n",
      "    C(g1_center, g2_center)       = +0.4939\n",
      "    C(g1_sigma, g2_center)        = +0.1550\n",
      "[23 40]\n",
      "2 component guess:  6558.9 6563.3\n",
      "[[Model]]\n",
      "    (Model(lorentzian, prefix='l1_') + Model(lorentzian, prefix='l2_'))\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 64\n",
      "    # data points      = 3170\n",
      "    # variables        = 6\n",
      "    chi-square         = 2.61395107\n",
      "    reduced chi-square = 8.2615e-04\n",
      "    Akaike info crit   = -22496.9780\n",
      "    Bayesian info crit = -22460.6091\n",
      "    R-squared          = 0.90667852\n",
      "[[Variables]]\n",
      "    l1_amplitude:  3.14118525 +/- 0.21322952 (6.79%) (init = 8)\n",
      "    l1_center:     6558.13731 +/- 0.07536957 (0.00%) (init = 6558.9)\n",
      "    l1_sigma:      2.25433334 +/- 0.12845704 (5.70%) (init = 3)\n",
      "    l2_amplitude:  9.62646142 +/- 0.24659516 (2.56%) (init = 8)\n",
      "    l2_center:     6563.81256 +/- 0.05985468 (0.00%) (init = 6563.3)\n",
      "    l2_sigma:      3.47819575 +/- 0.07768467 (2.23%) (init = 3)\n",
      "    l1_fwhm:       4.50866667 +/- 0.25691409 (5.70%) == '2.0000000*l1_sigma'\n",
      "    l1_height:     0.44353262 +/- 0.01433879 (3.23%) == '0.3183099*l1_amplitude/max(1e-15, l1_sigma)'\n",
      "    l2_fwhm:       6.95639149 +/- 0.15536933 (2.23%) == '2.0000000*l2_sigma'\n",
      "    l2_height:     0.88097341 +/- 0.01113575 (1.26%) == '0.3183099*l2_amplitude/max(1e-15, l2_sigma)'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(l1_amplitude, l2_amplitude) = -0.9129\n",
      "    C(l1_amplitude, l1_sigma)     = +0.8803\n",
      "    C(l2_amplitude, l2_sigma)     = +0.8698\n",
      "    C(l1_amplitude, l2_center)    = +0.7854\n",
      "    C(l1_sigma, l2_amplitude)     = -0.7543\n",
      "    C(l2_amplitude, l2_center)    = -0.7425\n",
      "    C(l1_amplitude, l2_sigma)     = -0.7388\n",
      "    C(l1_sigma, l2_center)        = +0.6159\n",
      "    C(l2_center, l2_sigma)        = -0.6102\n",
      "    C(l1_amplitude, l1_center)    = +0.6099\n",
      "    C(l1_center, l2_amplitude)    = -0.6092\n",
      "    C(l1_center, l2_center)       = +0.5992\n",
      "    C(l1_sigma, l2_sigma)         = -0.5418\n",
      "    C(l1_center, l1_sigma)        = +0.5213\n",
      "    C(l1_center, l2_sigma)        = -0.4229\n",
      "[23 40]\n",
      "2 component guess:  6558.9 6563.3\n",
      "[[Model]]\n",
      "    (Model(voigt, prefix='v1_') + Model(voigt, prefix='v2_'))\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 197\n",
      "    # data points      = 3170\n",
      "    # variables        = 6\n",
      "    chi-square         = 2.82528271\n",
      "    reduced chi-square = 8.9295e-04\n",
      "    Akaike info crit   = -22250.5246\n",
      "    Bayesian info crit = -22214.1557\n",
      "    R-squared          = 0.89913370\n",
      "[[Variables]]\n",
      "    v1_amplitude:  2.40565230 +/- 0.25190848 (10.47%) (init = 8)\n",
      "    v1_center:     6557.59865 +/- 0.11908889 (0.00%) (init = 6558.9)\n",
      "    v1_sigma:      1.34966441 +/- 0.08829572 (6.54%) (init = 3)\n",
      "    v2_amplitude:  9.56415738 +/- 0.29290610 (3.06%) (init = 8)\n",
      "    v2_center:     6563.65465 +/- 0.10493251 (0.00%) (init = 6563.3)\n",
      "    v2_sigma:      2.33771617 +/- 0.05808551 (2.48%) (init = 3)\n",
      "    v1_gamma:      1.34966441 +/- 0.08829572 (6.54%) == 'v1_sigma'\n",
      "    v1_fwhm:       4.86053379 +/- 0.31797854 (6.54%) == '1.0692*v1_gamma+sqrt(0.8664*v1_gamma**2+5.545083*v1_sigma**2)'\n",
      "    v1_height:     0.37200504 +/- 0.02092614 (5.63%) == '(v1_amplitude/(max(1e-15, v1_sigma*sqrt(2*pi))))*real(wofz((1j*v1_gamma)/(max(1e-15, v1_sigma*sqrt(2)))))'\n",
      "    v2_gamma:      2.33771617 +/- 0.05808551 (2.48%) == 'v2_sigma'\n",
      "    v2_fwhm:       8.41879536 +/- 0.20918280 (2.48%) == '1.0692*v2_gamma+sqrt(0.8664*v2_gamma**2+5.545083*v2_sigma**2)'\n",
      "    v2_height:     0.85387971 +/- 0.01093455 (1.28%) == '(v2_amplitude/(max(1e-15, v2_sigma*sqrt(2*pi))))*real(wofz((1j*v2_gamma)/(max(1e-15, v2_sigma*sqrt(2)))))'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(v1_amplitude, v2_amplitude) = -0.9490\n",
      "    C(v1_amplitude, v2_center)    = +0.9193\n",
      "    C(v2_amplitude, v2_sigma)     = +0.9142\n",
      "    C(v2_amplitude, v2_center)    = -0.8867\n",
      "    C(v1_amplitude, v1_sigma)     = +0.8817\n",
      "    C(v1_amplitude, v2_sigma)     = -0.8490\n",
      "    C(v1_sigma, v2_amplitude)     = -0.8000\n",
      "    C(v2_center, v2_sigma)        = -0.7968\n",
      "    C(v1_center, v2_center)       = +0.7954\n",
      "    C(v1_amplitude, v1_center)    = +0.7864\n",
      "    C(v1_center, v2_amplitude)    = -0.7854\n",
      "    C(v1_sigma, v2_center)        = +0.7669\n",
      "    C(v1_center, v1_sigma)        = +0.6855\n",
      "    C(v1_center, v2_sigma)        = -0.6506\n",
      "    C(v1_sigma, v2_sigma)         = -0.6457\n",
      "end of plotting\n"
     ]
    }
   ],
   "source": [
    "##### This segmnent reads from the csv database and analyses the spectra\n",
    "\n",
    "workdir = pathlib.Path.cwd() #get the initial working directory where this notebook is located\n",
    "print(\"Initial work directory: \",workdir)\n",
    "Source_Name=\"GX304-1\" #This is the source I am working with now\n",
    "Image_Dir = workdir / (Source_Name) #Add the source folder sub directory to save the work into\n",
    "# print(f\"Image saving directory for source {Source_Name} is {Image_Dir}\")\n",
    "\n",
    "Source_database = pd.read_csv(f'{Image_Dir}\\{Source_Name}_dataframe.csv') #read the specific source database csv file\n",
    "\n",
    "spectra_files=list(Image_Dir.glob(\"smb*.txt\"))\n",
    "file_Names=[]\n",
    "# print ((spectra_files))\n",
    "for i in range(0,len(spectra_files)):\n",
    "    file_Names.append(str(spectra_files[i])[66:])\n",
    "print(\"File names:\",file_Names)\n",
    "\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "\n",
    "    p=Source_database[\"Spec_Path\"][i]\n",
    "    print(f\"{Image_Dir}\\{p}\")\n",
    "    file = np.loadtxt(str(f\"{Image_Dir}\\{p}\")) # This imports the wavelength and normalised flux lists from each spectrum file listed in the database\n",
    "    x = file[:,0]\n",
    "    y = file[:,1]\n",
    "    \n",
    "    nameString = file_Names[i][15:27] + '_' + Source_Name #this string is used to name the new files created through analysis\n",
    "\n",
    "    #If statements to determine which kind of fit to do depending on \"type\" or the shape of the Halpha line profile\n",
    "    if(Source_database[\"Type\"][i]==1):\n",
    "        print(\"Single emission peak type spectrum\")\n",
    "        # LMfit_ALL_t1(Source_Name,nameString,x,y)\n",
    "        # break\n",
    "        \n",
    "\n",
    "    if(Source_database[\"Type\"][i]==2):\n",
    "        print(\"Double emission peak type spectrum\")\n",
    "        fit_T2_outputs = LMfit_ALL_t2(Source_Name, nameString, x, y)    #fit_T2_outputs[k] where k is 0 to 2, 0 is Gaussian, 1 is Lorentzian and 2 is Voigt outputs.\n",
    "                                                                        #fit_T2_outputs[k][i] where i is 0 to 7, running through Height1,Centre1,Width1,\n",
    "                                                                        #Height2,Centre2,Width2,V/D ratio, peak seperation in angstrom.\n",
    "\n",
    "        # Source_database[\"Peak_ratio\"][i]=fit_T2_outputs[1][6] #Choosing Lorentzian values as they seem best fit atm.\n",
    "        # Source_database[\"Peak_distance\"][i]=fit_T2_outputs[1][7]\n",
    "        break\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==3):\n",
    "        print(\"Single absorption valley type spectrum\")\n",
    "        # LMfit_ALL_t3(Source_Name, nameString, x, y)\n",
    "        break\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==4):\n",
    "        print(\"Absorption valley walled by emission wings type spectrum\")\n",
    "        # LMfit_ALL_t4(Source_Name, nameString, x, y)\n",
    "\n",
    "\n",
    "    if(Source_database[\"Type\"][i]==5):\n",
    "        print(\"Emission peak walled by absorption wings type spectrum\")\n",
    "        # LMfit_ALL_t5(Source_Name, nameString, x, y)\n",
    "        # break\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    # if (Source_database[\"Type\"][i]==5):\n",
    "    #     break\n",
    "    # break\n",
    "# Source_database.to_csv(f'{Image_Dir}\\{Source_Name}_dataframe_Updated.csv',index=False) #saving to different file name to make sure I do not mess things up with the original dataframe\n",
    "print(\"end of plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee1300d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "2456105 nan\n",
      "2456105 nan\n",
      "2456316 nan\n",
      "2456316 nan\n",
      "2456357 nan\n",
      "2456357 nan\n",
      "2456374 nan\n",
      "2456374 nan\n",
      "2456409 nan\n",
      "2456409 nan\n",
      "2456677 0.731\n",
      "2456677 0.738\n",
      "2456704 0.739\n",
      "2456704 0.75\n",
      "2456715 0.787\n",
      "2456715 0.8\n",
      "2456726 nan\n",
      "2456726 nan\n",
      "2456738 nan\n",
      "2456738 nan\n",
      "2456752 nan\n",
      "2456752 nan\n",
      "2456763 0.483\n",
      "2456763 0.485\n",
      "2456780 nan\n",
      "2456780 nan\n",
      "2456788 nan\n",
      "2456788 nan\n",
      "2456791 nan\n",
      "2456791 nan\n",
      "2456794 nan\n",
      "2456794 nan\n",
      "2456808 nan\n",
      "2456808 nan\n",
      "2456818 nan\n",
      "2456818 nan\n",
      "2456821 nan\n",
      "2457037 nan\n",
      "2457037 0.838\n",
      "2457042 0.782\n",
      "2457042 0.783\n",
      "2457056 0.893\n",
      "2457056 0.892\n",
      "2457064 0.796\n",
      "2457064 0.793\n",
      "2457072 0.824\n",
      "2457072 0.819\n",
      "2457078 0.768\n",
      "2457078 0.768\n",
      "2457540 nan\n",
      "2457556 nan\n",
      "2457557 nan\n",
      "2457563 nan\n",
      "2457568 nan\n",
      "2457778 nan\n",
      "2457799 nan\n",
      "2457826 nan\n",
      "2457843 nan\n",
      "2457856 nan\n",
      "2457909 nan\n",
      "2457935 nan\n",
      "2457945 nan\n",
      "2458134 nan\n",
      "2458261 nan\n",
      "2458294 nan\n",
      "2458510 nan\n",
      "2458520 nan\n",
      "2458530 nan\n",
      "2458540 nan\n",
      "2458553 nan\n",
      "2458564 nan\n",
      "2458860 nan\n",
      "2458926 nan\n",
      "2459003 nan\n",
      "2459031 nan\n",
      "2459058 nan\n",
      "2459670 nan\n",
      "2459670 nan\n",
      "2459749 nan\n",
      "2459749 nan\n",
      "2459773 nan\n",
      "2459773 nan\n",
      "2459787 nan\n",
      "2459787 nan\n",
      "2459795 nan\n",
      "2459795 nan\n",
      "2456105 nan\n",
      "2456105 nan\n",
      "2456316 nan\n",
      "2456316 nan\n",
      "2456357 nan\n",
      "2456357 nan\n",
      "2456374 nan\n",
      "2456374 nan\n",
      "2456409 nan\n",
      "2456409 nan\n",
      "2456677 0.731\n",
      "2456677 0.738\n",
      "2456704 0.739\n",
      "2456704 0.75\n",
      "2456715 0.787\n",
      "2456715 0.8\n",
      "2456726 nan\n",
      "2456726 nan\n",
      "2456738 nan\n",
      "2456738 nan\n",
      "2456752 nan\n",
      "2456752 nan\n",
      "2456763 0.483\n",
      "2456763 0.485\n",
      "2456780 nan\n",
      "2456780 nan\n",
      "2456788 nan\n",
      "2456788 nan\n",
      "2456791 nan\n",
      "2456791 nan\n",
      "2456794 nan\n",
      "2456794 nan\n",
      "2456808 nan\n",
      "2456808 nan\n",
      "2456818 nan\n",
      "2456818 nan\n",
      "2456821 nan\n",
      "2457037 nan\n",
      "2457037 0.838\n",
      "2457042 0.782\n",
      "2457042 0.783\n",
      "2457056 0.893\n",
      "2457056 0.892\n",
      "2457064 0.796\n",
      "2457064 0.793\n",
      "2457072 0.824\n",
      "2457072 0.819\n",
      "2457078 0.768\n",
      "2457078 0.768\n",
      "2457540 nan\n",
      "2457556 nan\n",
      "2457557 nan\n",
      "2457563 nan\n",
      "2457568 nan\n",
      "2457778 nan\n",
      "2457799 nan\n",
      "2457826 nan\n",
      "2457843 nan\n",
      "2457856 nan\n",
      "2457909 nan\n",
      "2457935 nan\n",
      "2457945 nan\n",
      "2458134 nan\n",
      "2458261 nan\n",
      "2458294 nan\n",
      "2458510 nan\n",
      "2458520 nan\n",
      "2458530 nan\n",
      "2458540 nan\n",
      "2458553 nan\n",
      "2458564 nan\n",
      "2458860 nan\n",
      "2458926 nan\n",
      "2459003 nan\n",
      "2459031 nan\n",
      "2459058 nan\n",
      "2459670 nan\n",
      "2459670 nan\n",
      "2459749 nan\n",
      "2459749 nan\n",
      "2459773 nan\n",
      "2459773 nan\n",
      "2459787 nan\n",
      "2459787 nan\n",
      "2459795 nan\n",
      "2459795 nan\n",
      "2456105 nan\n",
      "2456105 nan\n",
      "2456316 nan\n",
      "2456316 nan\n",
      "2456357 nan\n",
      "2456357 nan\n",
      "2456374 nan\n",
      "2456374 nan\n",
      "2456409 nan\n",
      "2456409 nan\n",
      "2456677 4.351\n",
      "2456677 4.351\n",
      "2456704 3.817\n",
      "2456704 4.071\n",
      "2456715 3.327\n",
      "2456715 3.327\n",
      "2456726 nan\n",
      "2456726 nan\n",
      "2456738 nan\n",
      "2456738 nan\n",
      "2456752 nan\n",
      "2456752 nan\n",
      "2456763 4.86\n",
      "2456763 4.604\n",
      "2456780 nan\n",
      "2456780 nan\n",
      "2456788 nan\n",
      "2456788 nan\n",
      "2456791 nan\n",
      "2456791 nan\n",
      "2456794 nan\n",
      "2456794 nan\n",
      "2456808 nan\n",
      "2456808 nan\n",
      "2456818 nan\n",
      "2456818 nan\n",
      "2456821 nan\n",
      "2457037 nan\n",
      "2457037 2.614\n",
      "2457042 3.136\n",
      "2457042 2.874\n",
      "2457056 3.135\n",
      "2457056 2.874\n",
      "2457064 3.31\n",
      "2457064 3.31\n",
      "2457072 3.014\n",
      "2457072 3.265\n",
      "2457078 3.053\n",
      "2457078 2.799\n",
      "2457540 nan\n",
      "2457556 nan\n",
      "2457557 nan\n",
      "2457563 nan\n",
      "2457568 nan\n",
      "2457778 nan\n",
      "2457799 nan\n",
      "2457826 nan\n",
      "2457843 nan\n",
      "2457856 nan\n",
      "2457909 nan\n",
      "2457935 nan\n",
      "2457945 nan\n",
      "2458134 nan\n",
      "2458261 nan\n",
      "2458294 nan\n",
      "2458510 nan\n",
      "2458520 nan\n",
      "2458530 nan\n",
      "2458540 nan\n",
      "2458553 nan\n",
      "2458564 nan\n",
      "2458860 nan\n",
      "2458926 nan\n",
      "2459003 nan\n",
      "2459031 nan\n",
      "2459058 nan\n",
      "2459670 nan\n",
      "2459670 nan\n",
      "2459749 nan\n",
      "2459749 nan\n",
      "2459773 nan\n",
      "2459773 nan\n",
      "2459787 nan\n",
      "2459787 nan\n",
      "2459795 nan\n",
      "2459795 nan\n",
      "2456105 nan\n",
      "2456105 nan\n",
      "2456316 nan\n",
      "2456316 nan\n",
      "2456357 nan\n",
      "2456357 nan\n",
      "2456374 nan\n",
      "2456374 nan\n",
      "2456409 nan\n",
      "2456409 nan\n",
      "2456677 4.351\n",
      "2456677 4.351\n",
      "2456704 3.817\n",
      "2456704 4.071\n",
      "2456715 3.327\n",
      "2456715 3.327\n",
      "2456726 nan\n",
      "2456726 nan\n",
      "2456738 nan\n",
      "2456738 nan\n",
      "2456752 nan\n",
      "2456752 nan\n",
      "2456763 4.86\n",
      "2456763 4.604\n",
      "2456780 nan\n",
      "2456780 nan\n",
      "2456788 nan\n",
      "2456788 nan\n",
      "2456791 nan\n",
      "2456791 nan\n",
      "2456794 nan\n",
      "2456794 nan\n",
      "2456808 nan\n",
      "2456808 nan\n",
      "2456818 nan\n",
      "2456818 nan\n",
      "2456821 nan\n",
      "2457037 nan\n",
      "2457037 2.614\n",
      "2457042 3.136\n",
      "2457042 2.874\n",
      "2457056 3.135\n",
      "2457056 2.874\n",
      "2457064 3.31\n",
      "2457064 3.31\n",
      "2457072 3.014\n",
      "2457072 3.265\n",
      "2457078 3.053\n",
      "2457078 2.799\n",
      "2457540 nan\n",
      "2457556 nan\n",
      "2457557 nan\n",
      "2457563 nan\n",
      "2457568 nan\n",
      "2457778 nan\n",
      "2457799 nan\n",
      "2457826 nan\n",
      "2457843 nan\n",
      "2457856 nan\n",
      "2457909 nan\n",
      "2457935 nan\n",
      "2457945 nan\n",
      "2458134 nan\n",
      "2458261 nan\n",
      "2458294 nan\n",
      "2458510 nan\n",
      "2458520 nan\n",
      "2458530 nan\n",
      "2458540 nan\n",
      "2458553 nan\n",
      "2458564 nan\n",
      "2458860 nan\n",
      "2458926 nan\n",
      "2459003 nan\n",
      "2459031 nan\n",
      "2459058 nan\n",
      "2459670 nan\n",
      "2459670 nan\n",
      "2459749 nan\n",
      "2459749 nan\n",
      "2459773 nan\n",
      "2459773 nan\n",
      "2459787 nan\n",
      "2459787 nan\n",
      "2459795 nan\n",
      "2459795 nan\n"
     ]
    }
   ],
   "source": [
    "##### Plot the time series data\n",
    "\n",
    "print(Source_database[\"Peak_ratio\"][0])\n",
    "\n",
    "\n",
    "Julian_dates=[]\n",
    "y_values=[]\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "    Julian_dates.append(Source_database[\"JD\"][i])\n",
    "    y_values.append(Source_database[\"Peak_ratio\"][i])\n",
    "    print(Julian_dates[i],y_values[i])\n",
    "\n",
    "\n",
    "plot_Time_Series_Data(Julian_dates,y_values,\"VtoR ratio\")\n",
    "\n",
    "Julian_dates=[]\n",
    "y_values=[]\n",
    "for i in range(0,len(Source_database[\"JD\"])):\n",
    "    Julian_dates.append(Source_database[\"JD\"][i])\n",
    "    y_values.append(Source_database[\"Peak_distance\"][i])\n",
    "    print(Julian_dates[i],y_values[i])\n",
    "\n",
    "plot_Time_Series_Data(Julian_dates,y_values,\"Peak_seperation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3ca0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
